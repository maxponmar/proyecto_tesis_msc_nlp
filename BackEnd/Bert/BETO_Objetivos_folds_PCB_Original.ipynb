{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfVkuWAW5r36"
      },
      "source": [
        ".64\n",
        "\n",
        "# Entrenando modelo BETO de detecta premisas y conclusiones en oraciones con PoC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0rpgtxmkET4"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfBvd7zVIbDc"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ-uJS-K1wA3"
      },
      "source": [
        "**Montar disco de Gdrive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlw58ZSc1yDe",
        "outputId": "94189ceb-2325-4d92-e371-3313da772a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I_XXNkkZ1yKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa07fbb9-3b63-4eaf-ae8b-bed0ef468b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold_0_test.txt   fold_2_train.txt  fold_5_test.txt   fold_7_train.txt\t fold_9_train.txt\n",
            "fold_0_train.txt  fold_3_test.txt   fold_5_train.txt  fold_8_test.txt\n",
            "fold_1_test.txt   fold_3_train.txt  fold_6_test.txt   fold_8_train.txt\n",
            "fold_1_train.txt  fold_4_test.txt   fold_6_train.txt  fold_9_test.txt\n",
            "fold_2_test.txt   fold_4_train.txt  fold_7_test.txt   fold_9_train.gdoc\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utGQ7w2Jjdi6"
      },
      "source": [
        "Download `transformers` and install required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "klEBSPAuIaDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e993691-0c68-4358-ac18-f0d5214d4902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 224049, done.\u001b[K\n",
            "remote: Counting objects: 100% (687/687), done.\u001b[K\n",
            "remote: Compressing objects: 100% (452/452), done.\u001b[K\n",
            "remote: Total 224049 (delta 372), reused 385 (delta 184), pack-reused 223362 (from 1)\u001b[K\n",
            "Receiving objects: 100% (224049/224049), 239.10 MiB | 17.04 MiB/s, done.\n",
            "Resolving deltas: 100% (162489/162489), done.\n",
            "/content/transformers\n",
            "Processing /content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2024.7.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9531229 sha256=4203a302b7d24ea122350fa76b4a656b5d0479c3ee8e08d96eb2f240a2846135\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2ndmzuua/wheels/7c/35/80/e946b22a081210c6642e607ed65b2a5b9a4d9259695ee2caf5\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed transformers-4.45.0.dev0\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './examples/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m/content\n"
          ]
        }
      ],
      "source": [
        "#%%capture\n",
        "!git clone https://github.com/huggingface/transformers\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iT0pMHt9K2sJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e2793f-10f2-4d82-bb1f-9a3c61917309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval (from -r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 1))\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets>=1.1.3 (from -r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2))\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (3.15.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2))\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (4.66.5)\n",
            "Collecting xxhash (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (3.10.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2024.7.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.1.3->-r /content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt (line 2)) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m186.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=f2dffae792ed84879b179c3bd1280dbfc403c9ed69c0e3b53e07b5a720dcc5a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: xxhash, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, seqeval, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pyarrow-17.0.0 seqeval-1.2.2 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "#usar info de huggigfaces\n",
        "# https://github.com/huggingface/transformers/tree/master/examples/token-classification\n",
        "\n",
        "# !wget -O 'requirements_tokenclasify.txt' \"https://raw.githubusercontent.com/huggingface/transformers/master/examples/token-classification/requirements.txt\"\n",
        "\n",
        "# !pip install -r \"/content/drive/MyDrive/Exp_Objetivos2021/config_ner/requirements.txt\"\n",
        "!pip install -r \"/content/drive/MyDrive/ColabNotebooks/BERT/Scripts/requirements.txt\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU8R8FeAIT2C"
      },
      "source": [
        "# Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8yUAiD-l64b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JELuvmOKJaq6"
      },
      "source": [
        "## 1. Download Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQXQAFDg7ZpP"
      },
      "source": [
        "Para deteccion de componentes\n",
        "\n",
        "   - dev.txt: Spanish test data for the development stage\n",
        "   - test.txt: Spanish test data\n",
        "   - train.txt: Spanish train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DPWj8VvrEeYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8522c1d5-6626-4a5c-c6ea-b8b0a6ce3310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold_0_test.txt   fold_2_train.txt  fold_5_test.txt   fold_7_train.txt\t fold_9_train.txt\n",
            "fold_0_train.txt  fold_3_test.txt   fold_5_train.txt  fold_8_test.txt\n",
            "fold_1_test.txt   fold_3_train.txt  fold_6_test.txt   fold_8_train.txt\n",
            "fold_1_train.txt  fold_4_test.txt   fold_6_train.txt  fold_9_test.txt\n",
            "fold_2_test.txt   fold_4_train.txt  fold_7_test.txt   fold_9_train.gdoc\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3c4v9IKJVjL"
      },
      "source": [
        "## 2. Preprocessing - quizas usar otro modelo bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gtQ-tVQWgWe"
      },
      "source": [
        "Let's define some variables that we need for further pre-processing steps and training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z4Wl3iR0UBZv"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 120 #@param {type: \"integer\"}\n",
        "MODEL = \"dccuchile/bert-base-spanish-wwm-uncased\"  #@param [\"chriskhanhtran/spanberta\", \"bert-base-multilingual-cased\",\"dccuchile/bert-base-spanish-wwm-uncased\", \"pysentimiento/robertuito-base-uncased\"]\n",
        "\n",
        "# dccuchile/bert-base-spanish-wwm-uncased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSfMYC7w_UpX"
      },
      "source": [
        "The script below will split sentences longer than `MAX_LENGTH` (in terms of tokens) into small ones. Otherwise, long sentences will be truncated when tokenized, causing the loss of training data and some tokens in the test set not being predicted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3gmazeojxn80"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !wget \"https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\"\n",
        "\n",
        "# !cp \"/content/drive/MyDrive/Exp_Objetivos2021/config_ner/preprocess.py\" \"/content/\"\n",
        "!cp \"/content/drive/MyDrive/ColabNotebooks/BERT/Scripts/preprocess.py\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RZHG9GDwFs3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ae36ca-9bf9-4a35-9a1b-6728bb1fd6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  preprocess.py  sample_data  transformers\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qn10UkLQxNg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebca031-5dc1-45b1-ac32-c15d5fe078d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 310/310 [00:00<00:00, 1.75MB/s]\n",
            "config.json: 100% 650/650 [00:00<00:00, 4.92MB/s]\n",
            "vocab.txt: 100% 248k/248k [00:00<00:00, 713kB/s]\n",
            "tokenizer.json: 100% 486k/486k [00:00<00:00, 933kB/s]\n",
            "special_tokens_map.json: 100% 134/134 [00:00<00:00, 767kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# !python3 preprocess.py ./drive/MyDrive/experimentosArgComp/datos_compOracionesArgC_folds/fold_0_train.txt $MODEL $MAX_LENGTH > train.txt\n",
        "# # !python3 preprocess.py ./drive/MyDrive/experimentosArgComp/datos_comp/fold_0_dev.txt $MODEL $MAX_LENGTH > dev.txt\n",
        "# !python3 preprocess.py ./drive/MyDrive/experimentosArgComp/datos_compOracionesArgC_folds/fold_0_test.txt $MODEL $MAX_LENGTH > test.txt\n",
        "\n",
        "\n",
        "!python3 preprocess.py /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE/fold_0_train.txt $MODEL $MAX_LENGTH > train.txt\n",
        "# # !python3 preprocess.py ./drive/MyDrive/experimentosArgComp/datos_comp/fold_0_dev.txt $MODEL $MAX_LENGTH > dev.txt\n",
        "!python3 preprocess.py /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE/fold_0_test.txt $MODEL $MAX_LENGTH > test.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SJQJHNlUNMP"
      },
      "source": [
        "## 3. Labels\n",
        "\n",
        "In comp, there are have X classes of NER tags:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-DlGoiJLqAR"
      },
      "source": [
        "- O, Outside of a component\n",
        "- B-Arg, Beginning of arg\n",
        "- I-Arg, arg entity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee3mlWe2BQPZ"
      },
      "source": [
        "If your dataset has different labels or more labels than CoNLL-2002/2003 datasets, run the line below to get unique labels from your data and save them into `labels.txt`. This file will be used when we start fine-tuning our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mEtntk5-Wnvu"
      },
      "outputs": [],
      "source": [
        "!cat train.txt  test.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt\n",
        "# !cat train.txt dev.txt test.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cTj6_KNwG28f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232cb740-8e14-41c2-c93f-f7bfc0d9b2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-QUE\n",
            "I-QUE\n",
            "O\n"
          ]
        }
      ],
      "source": [
        "!head -n20 labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zblM76vBWXOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9697b1fd-86ed-4f4a-aae8-01c48274b5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  labels.txt  preprocess.py  sample_data  test.txt  train.txt  transformers\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G80k0O2aWwzy"
      },
      "source": [
        "# Fine-tuning Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qy9XdmlJXqE"
      },
      "source": [
        "These are the example scripts from `transformers`'s repo that we will use to fine-tune our model for NER. After 04/21/2020, Hugging Face has updated their example scripts to use a new `Trainer` class. To avoid any future conflict, let's use the version before they made these updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aPVKv-jWWMZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116e9659-354f-4d5e-fc00-ca39f8551bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-5.0.1-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading conllu-5.0.1-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1NoEUI-EGDQp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !wget \"https://raw.githubusercontent.com/huggingface/transformers/master/examples/legacy/token-classification/run_ner.py\"\n",
        "# !wget \"https://raw.githubusercontent.com/huggingface/transformers/master/examples/legacy/token-classification/utils_ner.py\"\n",
        "# !wget \"https://raw.githubusercontent.com/huggingface/transformers/master/examples/legacy/token-classification/tasks.py\"\n",
        "\n",
        "\n",
        "# !cp \"/content/drive/MyDrive/Exp_Objetivos2021/config_ner/run_ner.py\" \"/content/\"\n",
        "# !cp \"/content/drive/MyDrive/Exp_Objetivos2021/config_ner/tasks.py\" \"/content/\"\n",
        "# !cp \"/content/drive/MyDrive/Exp_Objetivos2021/config_ner/utils_ner.py\" \"/content/\"\n",
        "\n",
        "\n",
        "!cp \"/content/drive/MyDrive/ColabNotebooks/BERT/Scripts/run_ner.py\" \"/content/\"\n",
        "!cp \"/content/drive/MyDrive/ColabNotebooks/BERT/Scripts/tasks.py\" \"/content/\"\n",
        "!cp \"/content/drive/MyDrive/ColabNotebooks/BERT/Scripts/utils_ner.py\" \"/content/\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VjEVTmraRfGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c93210-4eba-4074-d870-d394cd6a946d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\t    preprocess.py  sample_data\ttest.txt   transformers\n",
            "labels.txt  run_ner.py\t   tasks.py\ttrain.txt  utils_ner.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VKHUmZx8YfUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa908bac-d2bc-44cd-b3e8-446786cac6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold_0_test.txt   fold_2_train.txt  fold_5_test.txt   fold_7_train.txt\t fold_9_train.txt\n",
            "fold_0_train.txt  fold_3_test.txt   fold_5_train.txt  fold_8_test.txt\n",
            "fold_1_test.txt   fold_3_train.txt  fold_6_test.txt   fold_8_train.txt\n",
            "fold_1_train.txt  fold_4_test.txt   fold_6_train.txt  fold_9_test.txt\n",
            "fold_2_test.txt   fold_4_train.txt  fold_7_test.txt   fold_9_train.gdoc\n"
          ]
        }
      ],
      "source": [
        "# !ls /content/drive/MyDrive/Exp_Objetivos2021/folders\n",
        "!ls /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iCqP_-WeHQfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13cb707f-f941-4c6c-d100-93469afa3348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available combinations :  1 [(3e-05, 16, 160)]\n"
          ]
        }
      ],
      "source": [
        "# grid search\n",
        " # Model training\n",
        "max_accuracy = 0\n",
        "\n",
        "# epoch 4\n",
        "epoch = [160]   # 20 , 80,  160,  200     - 2, 3, 5, 10, 30, 60, 100, 200\n",
        "# batch sizes: 8, 16, 32, 64, 128\n",
        "# learning rates: 3e-4, 1e-4, 5e-5, 3e-5\n",
        "\n",
        "# learning_rate choices\n",
        "# learning_rates = [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05 ]\n",
        "learning_rates = [3e-5] #  3e-6\n",
        "\n",
        "# iterations choices\n",
        "# iterations = [ 100, 200, 300, 400, 500 ]\n",
        "batch = [16] # 16,32\n",
        "\n",
        "# #folds\n",
        "# folds = list(range(10))\n",
        "\n",
        "# available combination of learning_rate and iterations\n",
        "\n",
        "parameters = []\n",
        "for z  in epoch:\n",
        "    for j in batch:\n",
        "      for i in learning_rates:\n",
        "        parameters.append( ( i, j, z) )\n",
        "\n",
        "print(\"Available combinations : \",len(parameters),  parameters )\n",
        "\n",
        "\n",
        "# Applying linear searching in list of available combination\n",
        "# to achieved maximum accuracy on CV set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nU8AFzzIa22B"
      },
      "outputs": [],
      "source": [
        "  # dir = \"/content/drive/MyDrive/Exp_Objetivos2021/results/\"\n",
        "dir = \"/content/drive/MyDrive/ColabNotebooks/BERT/Results/\"\n",
        "\n",
        "# /content/drive/MyDrive/experimentosArgComp/results/22abrCorpus5arg\n",
        "# /content/drive/MyDrive/experimentosArgComp/sample_data\n",
        "# /content/drive/MyDrive/experimentosArgComp/results/BETOcorpus4compPCsolo\n",
        "\n",
        "f = open(dir+\"log_exp.txt\", \"a+\")\n",
        "log_text = f\"results\\n\"\n",
        "f.write(log_text)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TensorRT"
      ],
      "metadata": {
        "id": "TeDYwH009wOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab756203-efbb-4b22-8e01-260158bd6358"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TensorRT\n",
            "  Downloading tensorrt-10.3.0.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt-cu12==10.3.0 (from TensorRT)\n",
            "  Downloading tensorrt-cu12-10.3.0.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: TensorRT, tensorrt-cu12\n",
            "  Building wheel for TensorRT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TensorRT: filename=tensorrt-10.3.0-py2.py3-none-any.whl size=16337 sha256=2dc67d0e08eea04d6844ae9916e3bb884140253f86878b3a3c5af0b1883a7640\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/a8/32/bacdf7c14f627d34b90ce8586631e2f196e3fb0fd4eb9add55\n",
            "  Building wheel for tensorrt-cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.3.0-py2.py3-none-any.whl size=17554 sha256=72107b6379f48bb2a9b3ef164166bef837afc29311ebf3fd7430a1198173ad47\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/31/c2/a3ecb74def7087b76ef2a701e6823f03e40ab43348c668a571\n",
            "Successfully built TensorRT tensorrt-cu12\n",
            "Installing collected packages: tensorrt-cu12, TensorRT\n",
            "Successfully installed TensorRT-10.3.0 tensorrt-cu12-10.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "id": "O1_WCZukBurF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8032cb12-21df-42f1-c39a-f6beb98f9e71"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.32.1\n",
            "    Uninstalling accelerate-0.32.1:\n",
            "      Successfully uninstalled accelerate-0.32.1\n",
            "Successfully installed accelerate-0.33.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lqU8mvjIS_4D"
      },
      "outputs": [],
      "source": [
        "def read_examples_from_file(file_path):\n",
        "    \"\"\"Read words and labels from a CoNLL-2002/2003 data file.\n",
        "\n",
        "    Args:\n",
        "      file_path (str): path to NER data file.\n",
        "\n",
        "    Returns:\n",
        "      examples (dict): a dictionary with two keys: `words` (list of lists)\n",
        "        holding words in each sequence, and `labels` (list of lists) holding\n",
        "        corresponding labels.\n",
        "    \"\"\"\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        examples = {\"words\": [], \"labels\": []}\n",
        "        words = []\n",
        "        labels = []\n",
        "        for line in f:\n",
        "            if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
        "                if words:\n",
        "                    examples[\"words\"].append(words)\n",
        "                    examples[\"labels\"].append(labels)\n",
        "                    words = []\n",
        "                    labels = []\n",
        "            else:\n",
        "                splits = line.split(\" \")\n",
        "                words.append(splits[0])\n",
        "                if len(splits) > 1:\n",
        "                    labels.append(splits[-1].replace(\"\\n\", \"\"))\n",
        "                else:\n",
        "                    # Examples could have no label for mode = \"test\"\n",
        "                    labels.append(\"O\")\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WbjRXJw6HQjx",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a9d76e-aa49-47b9-c66f-0797fa6dd01f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:18:03.739104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:18:03.759605: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:18:03.766270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:18:03.782447: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:18:04.968241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:18:07 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:18:07 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-18-07_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:18:08,077 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:18:08,080 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:18:08,269 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:18:08,270 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:18:08,270 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:18:08,270 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:18:08,271 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:18:08,271 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:18:08,271 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:18:08,271 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:18:08,272 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "pytorch_model.bin: 100% 440M/440M [00:20<00:00, 21.0MB/s]\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:18:31,138 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:18:31,281 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:18:31,281 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - Writing example 0 of 324\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - tokens: [CLS] el objetivo del presente trabajo es estudiar y analizar la viabilidad de la implementación de un entre ##laz ##ado en tiempo de ejecución sobre la máquina virtual del proyecto mono ademas se estudiar ##á el impacto en el tiempo de carga y ejecución de la implementación utilizando una arquitectura escalo ##nada de experimenta ##cion [SEP]\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_ids: 4 1039 3073 1081 2807 1608 1028 6661 1040 10190 1032 18137 1009 1032 13811 1009 1044 1341 4424 1082 1035 1526 1009 4242 1246 1032 6055 15417 1081 2269 6172 27424 1057 6661 30980 1039 6501 1035 1039 1526 1009 5260 1040 4242 1009 1032 13811 7553 1091 8524 20977 20143 1009 20451 1105 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 1 1 -100 -100 1 1 1 1 1 1 1 1 1 1 1 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - tokens: [CLS] determinar la influencia de la implementación de un sistema de información basado en un enfoque de procesos en la opera ##tividad del área de créditos de la micro ##finan ##ciera crecer bajo una plataforma orientada a la w ##eb [SEP]\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_ids: 4 5679 1032 6135 1009 1032 13811 1009 1044 2074 1009 1926 6588 1035 1044 5877 1009 5676 1035 1032 2969 4767 1081 3967 1009 7701 1009 1032 6318 16796 15182 9457 2182 1091 7688 19515 1012 1032 1005 3686 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - tokens: [CLS] desarrollar una red de área local ( lan ) que facilite la comunicación en el centro local amazonas de la universidad nacional abierta . [SEP]\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_ids: 4 5201 1091 2946 1009 3967 3592 1147 2428 1135 1041 25162 1032 3617 1035 1039 2391 3592 21281 1009 1032 2862 1954 6051 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - tokens: [CLS] diseñar e implementar , un modelo de precisión para detectar y mitigar ph ##ishi ##ng en correos electrónicos utilizando técnicas actuales de minería de datos para aumentar el nivel de seguridad de los correos electrónicos . [SEP]\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_ids: 4 18043 1006 19118 1019 1044 4209 1009 11651 1097 13666 1040 22315 4398 29742 22396 1035 14256 12809 7553 5967 6966 1009 18596 1009 2783 1097 4928 1039 2174 1009 1955 1009 1067 14256 12809 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - tokens: [CLS] desarrollar un sistema de monitoreo basado en la tecnología de comunicación lor ##a para determinar la calidad del agua dulce que se consume en zonas rurales [SEP]\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_ids: 4 5201 1044 2074 1009 24624 6588 1035 1032 3925 1009 3617 6756 30956 1097 5679 1032 3339 1081 2326 5525 1041 1057 23893 1035 3762 8186 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:18:31 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:18:32,492 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:18:32,492 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:18:33,491 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:18:33,491 >>   Num examples = 324\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:18:33,491 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:18:33,491 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:18:33,491 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:18:33,491 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:18:33,491 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:18:33,491 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:18:33,492 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:32<04:01,  3.07it/s][INFO|trainer.py:3548] 2024-08-15 14:19:06,122 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:19:06,124 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:19:07,052 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            " 24% 200/840 [01:07<03:37,  2.94it/s][INFO|trainer.py:3548] 2024-08-15 14:19:40,804 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:19:40,806 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:19:41,704 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            " 36% 300/840 [01:43<03:12,  2.81it/s][INFO|trainer.py:3548] 2024-08-15 14:20:17,182 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:20:17,184 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:20:18,080 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:20:19,418 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 48% 400/840 [02:21<02:14,  3.27it/s][INFO|trainer.py:3548] 2024-08-15 14:20:54,621 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:20:54,623 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:20:55,511 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:20:56,813 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            "{'loss': 0.0251, 'grad_norm': 0.04810882359743118, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [02:58<02:01,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 14:21:31,538 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:21:31,540 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:21:32,384 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:21:33,727 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 71% 600/840 [03:35<01:26,  2.78it/s][INFO|trainer.py:3548] 2024-08-15 14:22:08,681 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:22:08,682 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:22:09,593 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:22:10,892 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            " 83% 700/840 [04:12<00:48,  2.87it/s][INFO|trainer.py:3548] 2024-08-15 14:22:45,527 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:22:45,528 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:22:46,420 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:22:47,765 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 95% 800/840 [04:49<00:12,  3.10it/s][INFO|trainer.py:3548] 2024-08-15 14:23:22,516 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:23:22,517 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:23:23,425 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:23:24,764 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            "100% 840/840 [05:05<00:00,  3.50it/s][INFO|trainer.py:3548] 2024-08-15 14:23:38,764 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:23:38,765 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:23:39,680 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:23:41,044 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            "[INFO|trainer.py:2420] 2024-08-15 14:23:41,254 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 307.762, 'train_samples_per_second': 42.11, 'train_steps_per_second': 2.729, 'train_loss': 0.015005351948950972, 'epoch': 40.0}\n",
            "100% 840/840 [05:07<00:00,  2.73it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 14:23:41,256 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:23:41,257 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:23:42,459 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 14:23:42,460 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 14:23:42,461 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - Writing example 0 of 40\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación [SEP]\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 5 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - tokens: [CLS] . [SEP]\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_ids: 4 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - label_ids: -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:23:42 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 14:23:42,611 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 14:23:42,611 >>   Num examples = 40\n",
            "[INFO|trainer.py:3869] 2024-08-15 14:23:42,611 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 12.65it/s]\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_loss = 0.953607439994812\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_accuracy_score = 0.8671328671328671\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_precision = 0.2033898305084746\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_recall = 0.3333333333333333\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_f1 = 0.2526315789473684\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_runtime = 0.4914\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_samples_per_second = 81.392\n",
            "08/15/2024 14:23:43 - INFO - __main__ -   test_steps_per_second = 10.174\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.8671328671328671 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold0\n",
            "\n",
            "test_f1 0.2526315789473684 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold0\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       0.72      0.83      0.77        35\n",
            "       I-QUE       0.74      0.58      0.65       431\n",
            "           O       0.89      0.94      0.92      1631\n",
            "\n",
            "    accuracy                           0.86      2097\n",
            "   macro avg       0.79      0.78      0.78      2097\n",
            "weighted avg       0.86      0.86      0.86      2097\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:24:01.478924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:24:01.499129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:24:01.505387: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:24:01.520060: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:24:02.670363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:24:04 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:24:04 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-24-04_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:24:05,184 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:24:05,188 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:24:05,386 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:24:05,387 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:24:05,387 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:24:05,387 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:24:05,387 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:24:05,387 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:24:05,387 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:24:05,388 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:24:05,388 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:24:05,798 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:24:05,873 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:24:05,873 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:24:05 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:24:06 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:24:07,090 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:24:07,090 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:24:07,984 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:24:07,984 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:24:07,984 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:24:07,984 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:24:07,984 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:24:07,984 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:24:07,984 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:24:07,984 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:24:07,985 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:35<04:31,  2.73it/s][INFO|trainer.py:3548] 2024-08-15 14:24:43,586 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:24:43,588 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:24:44,486 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:24:45,793 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:46,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:25:21,181 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:25:21,182 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:25:22,082 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:25:23,434 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:50<03:09,  2.86it/s][INFO|trainer.py:3548] 2024-08-15 14:25:58,019 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:25:58,020 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:25:58,912 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:26:00,217 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:27<02:18,  3.18it/s][INFO|trainer.py:3548] 2024-08-15 14:26:35,242 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:26:35,244 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:26:36,146 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:26:37,481 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0263, 'grad_norm': 0.0224518571048975, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:04<02:01,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 14:27:12,531 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:27:12,532 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:27:13,360 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:27:14,704 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:41<01:25,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 14:27:49,614 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:27:49,615 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:27:50,516 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:27:51,861 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:18<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:28:26,813 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:28:26,814 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:28:27,713 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:28:29,081 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [04:56<00:13,  3.07it/s][INFO|trainer.py:3548] 2024-08-15 14:29:04,003 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:29:04,004 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:29:05,223 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:12<00:00,  3.35it/s][INFO|trainer.py:3548] 2024-08-15 14:29:20,667 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:29:20,668 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:29:21,954 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 14:29:23,451 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 315.4666, 'train_samples_per_second': 41.336, 'train_steps_per_second': 2.663, 'train_loss': 0.015816536217573143, 'epoch': 40.0}\n",
            "100% 840/840 [05:15<00:00,  2.66it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 14:29:23,453 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:29:23,455 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:29:24,570 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 14:29:24,571 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 14:29:24,572 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - tokens: [CLS] el objetivo del presente trabajo es estudiar y analizar la viabilidad de la implementación de un entre ##laz ##ado en tiempo de ejecución sobre la máquina virtual del proyecto mono ademas se estudiar ##á el impacto en el tiempo de carga y ejecución de la implementación utilizando una arquitectura escalo ##nada de experimenta ##cion [SEP]\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_ids: 4 1039 3073 1081 2807 1608 1028 6661 1040 10190 1032 18137 1009 1032 13811 1009 1044 1341 4424 1082 1035 1526 1009 4242 1246 1032 6055 15417 1081 2269 6172 27424 1057 6661 30980 1039 6501 1035 1039 1526 1009 5260 1040 4242 1009 1032 13811 7553 1091 8524 20977 20143 1009 20451 1105 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 1 1 -100 -100 1 1 1 1 1 1 1 1 1 1 1 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - tokens: [CLS] determinar la influencia de la implementación de un sistema de información basado en un enfoque de procesos en la opera ##tividad del área de créditos de la micro ##finan ##ciera crecer bajo una plataforma orientada a la w ##eb [SEP]\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_ids: 4 5679 1032 6135 1009 1032 13811 1009 1044 2074 1009 1926 6588 1035 1044 5877 1009 5676 1035 1032 2969 4767 1081 3967 1009 7701 1009 1032 6318 16796 15182 9457 2182 1091 7688 19515 1012 1032 1005 3686 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - tokens: [CLS] desarrollar una red de área local ( lan ) que facilite la comunicación en el centro local amazonas de la universidad nacional abierta . [SEP]\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_ids: 4 5201 1091 2946 1009 3967 3592 1147 2428 1135 1041 25162 1032 3617 1035 1039 2391 3592 21281 1009 1032 2862 1954 6051 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - tokens: [CLS] diseñar e implementar , un modelo de precisión para detectar y mitigar ph ##ishi ##ng en correos electrónicos utilizando técnicas actuales de minería de datos para aumentar el nivel de seguridad de los correos electrónicos . [SEP]\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_ids: 4 18043 1006 19118 1019 1044 4209 1009 11651 1097 13666 1040 22315 4398 29742 22396 1035 14256 12809 7553 5967 6966 1009 18596 1009 2783 1097 4928 1039 2174 1009 1955 1009 1067 14256 12809 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - tokens: [CLS] desarrollar un sistema de monitoreo basado en la tecnología de comunicación lor ##a para determinar la calidad del agua dulce que se consume en zonas rurales [SEP]\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_ids: 4 5201 1044 2074 1009 24624 6588 1035 1032 3925 1009 3617 6756 30956 1097 5679 1032 3339 1081 2326 5525 1041 1057 23893 1035 3762 8186 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:24 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 14:29:24,684 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 14:29:24,684 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 14:29:24,684 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 14.58it/s]\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_loss = 0.3231450915336609\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_accuracy_score = 0.9563350035790981\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_precision = 0.6578947368421053\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_recall = 0.6944444444444444\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_f1 = 0.6756756756756757\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_runtime = 0.4245\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_samples_per_second = 84.796\n",
            "08/15/2024 14:29:25 - INFO - __main__ -   test_steps_per_second = 11.777\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9563350035790981 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold1\n",
            "\n",
            "test_f1 0.6756756756756757 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold1\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       0.97      0.97      0.97        35\n",
            "       I-QUE       0.89      0.88      0.89       267\n",
            "           O       0.97      0.97      0.97      1047\n",
            "\n",
            "    accuracy                           0.95      1349\n",
            "   macro avg       0.94      0.94      0.94      1349\n",
            "weighted avg       0.95      0.95      0.95      1349\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:29:41.748422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:29:41.768697: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:29:41.774996: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:29:41.789523: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:29:42.935814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:29:45 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:29:45 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-29-45_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:29:45,350 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:29:45,353 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:29:45,554 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:29:45,555 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:29:45,556 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:29:45,556 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:29:45,556 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:29:45,556 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:29:45,556 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:29:45,556 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:29:45,557 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:29:45,831 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:29:45,906 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:29:45,907 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:29:45 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:29:46 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:29:47,060 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:29:47,060 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:29:47,926 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:29:47,926 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:29:47,926 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:29:47,926 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:29:47,926 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:29:47,926 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:29:47,926 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:29:47,926 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:29:47,927 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:35<04:32,  2.71it/s][INFO|trainer.py:3548] 2024-08-15 14:30:23,627 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:30:23,629 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:30:24,528 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:30:25,904 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:46,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:31:01,259 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:31:01,260 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:31:02,170 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:31:03,612 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:50<03:08,  2.86it/s][INFO|trainer.py:3548] 2024-08-15 14:31:38,175 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:31:38,177 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:31:39,076 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:31:40,407 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:27<02:19,  3.16it/s][INFO|trainer.py:3548] 2024-08-15 14:32:15,549 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:32:15,551 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:32:16,481 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:32:17,917 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0265, 'grad_norm': 0.009403252974152565, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:05<02:01,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 14:32:52,968 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:32:52,969 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:32:53,822 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:32:55,247 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:42<01:26,  2.78it/s][INFO|trainer.py:3548] 2024-08-15 14:33:30,123 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:33:30,125 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:33:31,059 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:33:32,463 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:19<00:49,  2.82it/s][INFO|trainer.py:3548] 2024-08-15 14:34:07,413 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:34:07,414 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:34:08,356 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:34:09,732 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [04:56<00:13,  3.06it/s][INFO|trainer.py:3548] 2024-08-15 14:34:44,651 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:34:44,652 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:34:45,783 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:13<00:00,  3.36it/s][INFO|trainer.py:3548] 2024-08-15 14:35:01,088 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:35:01,089 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:35:02,284 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 14:35:03,763 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 315.8359, 'train_samples_per_second': 41.287, 'train_steps_per_second': 2.66, 'train_loss': 0.01582087359080712, 'epoch': 40.0}\n",
            "100% 840/840 [05:15<00:00,  2.66it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 14:35:03,765 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:35:03,766 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:35:04,913 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 14:35:04,915 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 14:35:04,915 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - tokens: [CLS] aplicar en casos prácticos los conocimientos teóricos adquiridos a lo largo del estudio de la licenciatura con la participación de diferentes instituciones educativas y de investigación de forma libre y abierta , que sea capaz de ofrecer , intercambiar y difundir material biblio ##gráfico en internet con la participación de diferentes instituciones educativas y de investigación de forma libre y abierta . [SEP]\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_ids: 4 5358 1035 3089 15367 1067 5923 25118 21968 1012 1086 2777 1081 3362 1009 1032 20345 1048 1032 3374 1009 3055 3673 16716 1040 1009 2764 1009 1795 2849 1040 6051 1019 1041 1787 4899 1009 5352 1019 16708 1040 14048 4405 5739 7633 1035 4730 1048 1032 3374 1009 3055 3673 16716 1040 1009 2764 1009 1795 2849 1040 6051 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - tokens: [CLS] desarrollar un prototipo de sistema de seguridad multi ##fun ##ción basado en la solución ut ##m , utilizando hard ##w ##are libre , para incrementar la seguridad de red de las organizaciones y los usuarios [SEP]\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_ids: 4 5201 1044 18643 1009 2074 1009 1955 4284 20846 1065 6588 1035 1032 4667 17795 30967 1019 7553 11722 1004 3992 2849 1019 1097 11188 1032 1955 1009 2946 1009 1085 3027 1040 1067 6637 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - tokens: [CLS] desarrollar una plataforma w ##eb colabora ##tiva para el análisis y seguimiento de la variación de precios oferta ##dos en los supermercados de la ciudad de quito utilizando la información extra ##ída de facturas electrónicas , con el fin de reducir el gasto en la economía familiar . [SEP]\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_ids: 4 5201 1091 7688 1005 3686 16693 1551 1097 1039 4089 1040 5852 1009 1032 16366 1009 4661 5972 1443 1035 1067 30906 1009 1032 1698 1009 15681 7553 1032 1926 2256 6477 1009 20560 20945 1019 1048 1039 1346 1009 4952 1039 10815 1035 1032 4399 3981 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 -100 1 -100 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - tokens: [CLS] desarrollar un sistema de información geográfico para la administración y monitoreo de la producción de los productos agropecu ##arios en las parroquias rurales del cantón rum ##i ##ña ##hu ##i , mediante la recolección de datos de la comunidad de agricultores . [SEP]\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_ids: 4 5201 1044 2074 1009 1926 19158 1097 1032 3764 1040 24624 1009 1032 3112 1009 1067 2776 24109 1781 1035 1085 23819 8186 1081 11896 5832 30961 1591 4139 30961 1019 2811 1032 21575 1009 2783 1009 1032 2291 1009 11749 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - tokens: [CLS] proporcionar una guía para detectar fallos en equipos conmu ##tadores de datos en una red lan usando como herramienta mp ##i ( mensaje pass ##ing interfa ##ce ) [SEP]\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_ids: 4 6776 1091 6689 1097 13666 17329 1035 4397 30248 6398 1009 2783 1035 1091 2946 2428 6275 1151 9825 21236 30961 1147 4202 27211 1623 14482 1187 1135 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:04 - INFO - utils_ner - label_ids: -100 0 1 1 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:05 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 14:35:05,019 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 14:35:05,019 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 14:35:05,019 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 15.54it/s]\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_loss = 0.3175989091396332\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_accuracy_score = 0.9474452554744526\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_precision = 0.5384615384615384\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_recall = 0.5833333333333334\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_f1 = 0.5599999999999999\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_runtime = 0.4032\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_samples_per_second = 89.286\n",
            "08/15/2024 14:35:05 - INFO - __main__ -   test_steps_per_second = 12.401\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9474452554744526 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold2\n",
            "\n",
            "test_f1 0.5599999999999999 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold2\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       1.00      1.00      1.00        35\n",
            "       I-QUE       0.89      0.83      0.86       263\n",
            "           O       0.96      0.97      0.97      1044\n",
            "\n",
            "    accuracy                           0.95      1342\n",
            "   macro avg       0.95      0.94      0.94      1342\n",
            "weighted avg       0.95      0.95      0.95      1342\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:35:22.179583: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:35:22.200279: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:35:22.206753: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:35:22.222443: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:35:23.411672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:35:25 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:35:25 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-35-25_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:35:25,849 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:35:25,852 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:35:26,045 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:35:26,046 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:35:26,046 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:35:26,046 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:35:26,046 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:35:26,046 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:35:26,046 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:35:26,047 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:35:26,047 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:35:26,327 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:35:26,402 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:35:26,402 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:35:26 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:35:27 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:35:27,572 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:35:27,572 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:35:28,443 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:35:28,443 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:35:28,443 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:35:28,443 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:35:28,443 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:35:28,443 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:35:28,443 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:35:28,443 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:35:28,444 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:36<04:35,  2.68it/s][INFO|trainer.py:3548] 2024-08-15 14:36:04,558 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:36:04,560 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:36:05,461 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:36:06,943 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:44,  2.85it/s][INFO|trainer.py:3548] 2024-08-15 14:36:42,010 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:36:42,011 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:36:42,919 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:36:44,307 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:51<03:10,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:37:19,970 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:37:19,971 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:37:20,867 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:37:22,215 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:28<02:18,  3.17it/s][INFO|trainer.py:3548] 2024-08-15 14:37:57,301 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:37:57,303 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:37:58,195 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:37:59,524 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0265, 'grad_norm': 0.014215740375220776, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:06<02:01,  2.81it/s][INFO|trainer.py:3548] 2024-08-15 14:38:34,561 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:38:34,562 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:38:35,400 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:38:36,694 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:43<01:25,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 14:39:11,594 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:39:11,595 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:39:12,501 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:39:13,862 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:20<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:39:48,918 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:39:48,919 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:39:49,818 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:39:51,293 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [04:57<00:13,  3.07it/s][INFO|trainer.py:3548] 2024-08-15 14:40:26,175 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:40:26,176 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:40:27,365 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:14<00:00,  3.36it/s][INFO|trainer.py:3548] 2024-08-15 14:40:42,824 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:40:42,825 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:40:43,996 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 14:40:46,757 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 318.3127, 'train_samples_per_second': 40.966, 'train_steps_per_second': 2.639, 'train_loss': 0.01588930252584673, 'epoch': 40.0}\n",
            "100% 840/840 [05:18<00:00,  2.64it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 14:40:46,759 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:40:46,760 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:40:47,774 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 14:40:47,776 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 14:40:47,776 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - tokens: [CLS] val ##idar el método de evaluación elaborado , usando la técnica del ##ph ##i con la finalidad de rec ##tificar , en caso de existir consideraciones hechas por los expertos . [SEP]\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_ids: 4 1590 7441 1039 6385 1009 4150 10254 1019 6275 1032 4274 1081 3370 30961 1048 1032 10308 1009 1640 23302 1019 1035 2053 1009 10597 14127 11303 1076 1067 4866 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - label_ids: -100 0 -100 1 1 1 1 1 2 2 2 2 2 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - tokens: [CLS] desarrollar un prototipo de un sistema de instrucción de tiro para el entrenamiento del personal de las fuerzas armadas , usando realidad virtual y tecn ##icas de inteligencia artificial . [SEP]\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_ids: 4 5201 1044 18643 1009 1044 2074 1009 11360 1009 6236 1097 1039 8222 1081 2613 1009 1085 3604 9422 1019 6275 2870 15417 1040 2810 1800 1009 6872 13937 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - tokens: [CLS] diseñar un sistema de visualización de zonas disponibles de aparcamiento en una zona determinada de un estacionamiento , basado en procesamiento de imágenes y el uso de tecnología bot [SEP]\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_ids: 4 18043 1044 2074 1009 29996 1009 3762 6375 1009 18227 1035 1091 2911 12428 1009 1044 14349 1019 6588 1035 14169 1009 6220 1040 1039 2889 1009 3925 25830 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - tokens: [CLS] diseñar un modelo que permita la captura de imágenes y posteriormente el procesamiento de la misma para que mediante algoritmo ##s de procesamiento indique si la plaza de estacionamiento se encuentra disponible . [SEP]\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_ids: 4 18043 1044 4209 1041 9983 1032 12133 1009 6220 1040 4571 1039 14169 1009 1032 2506 1097 1041 2811 23497 30958 1009 14169 21894 1096 1032 5450 1009 14349 1057 2562 6110 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - tokens: [CLS] desarrollar un prototipo de aplicación para la medición del estrés aplicando music ##ot ##era ##pia a estudiantes de ingeniería en sistemas e informática de la universidad de las fuerzas armadas espe [SEP]\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_ids: 4 5201 1044 18643 1009 2407 1097 1032 15391 1081 12857 14806 10623 8413 1178 6613 1012 4932 1009 9123 1035 3751 1006 14434 1009 1032 2862 1009 1085 3604 9422 13858 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 2 2 2 2 2 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:40:47 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 14:40:47,872 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 14:40:47,872 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 14:40:47,872 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 15.11it/s]\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_loss = 0.20149503648281097\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_accuracy_score = 0.9701365187713311\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_precision = 0.75\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_recall = 0.75\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_f1 = 0.75\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_runtime = 0.4123\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_samples_per_second = 87.315\n",
            "08/15/2024 14:40:48 - INFO - __main__ -   test_steps_per_second = 12.127\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9701365187713311 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold3\n",
            "\n",
            "test_f1 0.75 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold3\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       1.00      1.00      1.00        35\n",
            "       I-QUE       0.90      0.93      0.91       199\n",
            "           O       0.98      0.98      0.98       901\n",
            "\n",
            "    accuracy                           0.97      1135\n",
            "   macro avg       0.96      0.97      0.96      1135\n",
            "weighted avg       0.97      0.97      0.97      1135\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:41:05.319383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:41:05.340431: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:41:05.347051: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:41:05.362430: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:41:06.621299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:41:08 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:41:08 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-41-08_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:41:09,108 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:41:09,112 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:41:09,312 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:41:09,313 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:41:09,314 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:41:09,314 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:41:09,314 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:41:09,314 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:41:09,314 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:41:09,314 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:41:09,315 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:41:09,597 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:41:09,675 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:41:09,676 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:41:09 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:41:10 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:41:10,876 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:41:10,876 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:41:11,758 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:41:11,758 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:41:11,758 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:41:11,758 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:41:11,758 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:41:11,758 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:41:11,758 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:41:11,758 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:41:11,759 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:35<04:36,  2.68it/s][INFO|trainer.py:3548] 2024-08-15 14:41:47,579 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:41:47,580 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:41:48,483 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:41:49,767 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:44,  2.85it/s][INFO|trainer.py:3548] 2024-08-15 14:42:24,989 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:42:24,990 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:42:25,899 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:42:27,262 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:50<03:09,  2.85it/s][INFO|trainer.py:3548] 2024-08-15 14:43:01,804 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:43:01,805 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:43:02,713 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:43:04,011 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:27<02:18,  3.18it/s][INFO|trainer.py:3548] 2024-08-15 14:43:39,160 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:43:39,161 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:43:40,056 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:43:41,381 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.026, 'grad_norm': 0.007113781291991472, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:06<02:01,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 14:44:17,943 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:44:17,944 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:44:18,790 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:44:20,189 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:45<01:26,  2.78it/s][INFO|trainer.py:3548] 2024-08-15 14:44:57,377 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:44:57,379 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:44:58,311 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:44:59,786 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:22<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:45:34,758 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:45:34,759 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:45:35,682 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:45:37,060 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [05:00<00:13,  3.06it/s][INFO|trainer.py:3548] 2024-08-15 14:46:11,905 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:46:11,907 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:46:13,121 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:16<00:00,  3.36it/s][INFO|trainer.py:3548] 2024-08-15 14:46:28,496 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:46:28,498 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:46:29,727 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 14:46:31,247 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 319.4878, 'train_samples_per_second': 40.815, 'train_steps_per_second': 2.629, 'train_loss': 0.01566179863044194, 'epoch': 40.0}\n",
            "100% 840/840 [05:19<00:00,  2.63it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 14:46:31,249 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:46:31,250 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:46:32,338 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 14:46:32,341 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 14:46:32,341 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - tokens: [CLS] desarrollar un método alternativo de ingreso de credenciales basado en el uso de dispositivos móviles para disminuir el robo de estas por medio de herramientas de sp ##y ##w ##are conocidas como key ##log ##gers . [SEP]\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_ids: 4 5201 1044 6385 15989 1009 9011 1009 20860 6588 1035 1039 2889 1009 10571 12973 1097 15159 1039 5906 1009 1932 1076 2079 1009 8226 1009 4888 30976 1004 3992 12345 1151 23910 5520 11961 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 2 2 2 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - tokens: [CLS] implementar un soft ##w ##are para la evaluación del plan de vuelo y registro del personal militar en el simula ##dor de deso ##rie ##n ##tación espacial para el centro de investigación cien ##tifica y tecnológica , utilizando dos simula ##dores de vuelos comerciales [SEP]\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_ids: 4 19118 1044 7193 1004 3992 1097 1032 4150 1081 1584 1009 5845 1040 4975 1081 2613 2975 1035 1039 20800 2436 1009 13441 6529 30959 1660 8079 1097 1039 2391 1009 2764 2452 8391 1040 13614 1019 7553 1411 20800 5904 1009 11445 5590 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - label_ids: -100 0 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - tokens: [CLS] proponer una metodología que permita realizar la verificación de un pasaporte electrónico , val ##idan ##do la autenticidad de los datos contenidos en el ci sin contacto . [SEP]\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_ids: 4 13279 1091 14116 1041 9983 4267 1032 11536 1009 1044 13525 7523 1019 1590 19435 1050 1032 29475 1009 1067 2783 10636 1035 1039 1565 1320 4192 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - label_ids: -100 0 1 1 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - tokens: [CLS] aplicar técnicas de análisis predic ##tivo sobre un flujo de datos provenientes de una w ##ire ##less sensor net ##w ##ork ( red inalám ##brica de sensores ) , que permitan mejorar la toma de decisiones aplicadas a un caso de estudio [SEP]\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_ids: 4 5358 5967 1009 4089 9507 1483 1246 1044 10360 1009 2783 14645 1009 1091 1005 2598 21710 19525 12642 1004 3202 1147 2946 21766 15741 1009 17242 1135 1019 1041 11603 3888 1032 2912 1009 4005 19638 1012 1044 2053 1009 3362 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 -100 2 2 2 2 2 2 2 2 2 -100 -100 2 2 -100 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - tokens: [CLS] val ##idar el modelo predic ##tivo para la determinación de las zonas de exceso de velocidad mediante el test ##eo de la información obtenida en la investigación para verificar su precisión [SEP]\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_ids: 4 1590 7441 1039 4209 9507 1483 1097 1032 7713 1009 1085 3762 1009 13345 1009 5029 2811 1039 13444 1784 1009 1032 1926 20770 1035 1032 2764 1097 14030 1069 11651 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - label_ids: -100 0 -100 1 1 1 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:32 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 14:46:32,441 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 14:46:32,441 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 14:46:32,441 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 16.05it/s]\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_loss = 0.20748628675937653\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_accuracy_score = 0.9754816112084063\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_precision = 0.7837837837837838\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_recall = 0.8055555555555556\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_f1 = 0.7945205479452055\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_runtime = 0.3931\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_samples_per_second = 91.572\n",
            "08/15/2024 14:46:32 - INFO - __main__ -   test_steps_per_second = 12.718\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9754816112084063 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold4\n",
            "\n",
            "test_f1 0.7945205479452055 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold4\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       0.97      0.97      0.97        35\n",
            "       I-QUE       1.00      0.87      0.93       204\n",
            "           O       0.97      1.00      0.98       876\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.95      0.96      1115\n",
            "weighted avg       0.98      0.97      0.97      1115\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:46:49.594365: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:46:49.620041: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:46:49.626742: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:46:49.641598: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:46:50.813768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:46:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:46:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-46-52_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:46:53,213 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:46:53,217 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:46:53,414 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:46:53,415 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:46:53,415 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:46:53,416 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:46:53,416 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:46:53,416 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:46:53,416 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:46:53,416 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:46:53,417 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:46:53,729 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:46:53,804 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:46:53,804 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:46:53 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:46:54 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:46:54,970 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:46:54,970 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:46:55,830 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:46:55,830 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:46:55,830 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:46:55,830 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:46:55,830 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:46:55,830 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:46:55,830 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:46:55,830 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:46:55,831 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:35<04:35,  2.69it/s][INFO|trainer.py:3548] 2024-08-15 14:47:31,757 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:47:31,759 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:47:32,674 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:47:34,124 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:45,  2.84it/s][INFO|trainer.py:3548] 2024-08-15 14:48:09,293 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:48:09,294 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:48:10,211 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:48:11,610 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:50<03:09,  2.84it/s][INFO|trainer.py:3548] 2024-08-15 14:48:46,354 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:48:46,355 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:48:47,256 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:48:48,565 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:27<02:18,  3.17it/s][INFO|trainer.py:3548] 2024-08-15 14:49:23,627 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:49:23,628 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:49:24,548 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:49:25,969 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0265, 'grad_norm': 0.01651204191148281, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:05<02:00,  2.82it/s][INFO|trainer.py:3548] 2024-08-15 14:50:00,976 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:50:00,977 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:50:01,840 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:50:03,217 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:42<01:26,  2.79it/s][INFO|trainer.py:3548] 2024-08-15 14:50:38,101 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:50:38,103 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:50:38,996 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:50:40,306 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:19<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:51:15,239 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:51:15,241 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:51:16,144 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:51:17,578 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [04:56<00:13,  3.07it/s][INFO|trainer.py:3548] 2024-08-15 14:51:52,500 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:51:52,501 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:51:53,713 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:13<00:00,  3.35it/s][INFO|trainer.py:3548] 2024-08-15 14:52:09,140 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:52:09,141 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:52:10,355 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 14:52:12,382 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 316.5508, 'train_samples_per_second': 41.194, 'train_steps_per_second': 2.654, 'train_loss': 0.015828053187578916, 'epoch': 40.0}\n",
            "100% 840/840 [05:16<00:00,  2.65it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 14:52:12,384 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:52:12,385 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:52:14,741 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 14:52:14,743 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 14:52:14,743 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - tokens: [CLS] realizar un análisis compara ##tivo de fra ##me ##w ##orks para el desarrollo de aplicaciones móviles aplicando un modelo de calidad , caso de estudio en empresa sof ##ya system ##s s . a [SEP]\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_ids: 4 4267 1044 4089 11542 1483 1009 3077 1190 1004 23790 1097 1039 1766 1009 8236 12973 14806 1044 4209 1009 3339 1019 2053 1009 3362 1035 3312 6913 1742 22346 30958 1015 1008 1012 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - label_ids: -100 0 1 1 1 -100 1 1 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - tokens: [CLS] mejorar el análisis de vulnerabilidad ##es de las universidades miembros de ce ##dia aplicando business intel ##lig ##ence , con el fin de mitigar el impacto de los incidentes . [SEP]\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_ids: 4 3888 1039 4089 1009 14920 1018 1009 1085 9264 2014 1009 1651 1913 14806 22212 25505 1865 8538 1019 1048 1039 1346 1009 22315 1039 6501 1009 1067 14107 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 -100 1 1 1 2 2 2 -100 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - tokens: [CLS] desarrollar una aplicación móvil multi ##pla ##ta ##forma utilizando realidad aumenta ##da para la administración de la carga hora ##ria en los laboratorios de computación de la universidad espe [SEP]\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_ids: 4 5201 1091 2407 6803 4284 8983 1047 6150 7553 2870 10081 1167 1097 1032 3764 1009 1032 5260 2447 3886 1035 1067 15784 1009 25466 1009 1032 2862 13858 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 -100 -100 -100 2 2 2 -100 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - tokens: [CLS] desarrollar una aplicación w ##eb que permita visual ##izar mediciones de temperatura y humedad de suelo por medio del uso de redes de sensores inalám ##brico ##s ( w ##s ##n ) con el fin de conocer los niveles e indicadores principales resultantes del análisis previo de implantación . [SEP]\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_ids: 4 5201 1091 2407 1005 3686 1041 9983 11606 4057 24470 1009 7017 1040 14640 1009 4606 1076 2079 1081 2889 1009 5817 1009 17242 21766 29114 30958 1147 1005 30958 30959 1135 1048 1039 1346 1009 3266 1067 4708 1006 8474 3406 17398 1081 4089 10576 1009 19551 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - label_ids: -100 0 1 1 1 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - tokens: [CLS] comparar herramientas orientadas a w ##eb componen ##ts mediante el uso de una norma iso / ie ##c 91 ##2 ##6 , para el desarrollo de aplicaciones , con un caso práctico . [SEP]\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_ids: 4 16932 8226 20935 1012 1005 3686 18188 2415 2811 1039 2889 1009 1091 5088 15023 989 16823 30965 5700 30989 1000 1019 1097 1039 1766 1009 8236 1019 1048 1044 2053 13094 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 -100 1 -100 2 2 2 2 2 2 2 -100 -100 -100 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:14 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 14:52:14,850 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 14:52:14,850 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 14:52:14,850 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 15.08it/s]\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_loss = 0.29800188541412354\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_accuracy_score = 0.9669711876317639\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_precision = 0.6410256410256411\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_recall = 0.6944444444444444\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_f1 = 0.6666666666666666\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_runtime = 0.4126\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_samples_per_second = 87.255\n",
            "08/15/2024 14:52:15 - INFO - __main__ -   test_steps_per_second = 12.119\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9669711876317639 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold5\n",
            "\n",
            "test_f1 0.6666666666666666 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold5\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       1.00      1.00      1.00        35\n",
            "       I-QUE       0.99      0.83      0.90       257\n",
            "           O       0.96      1.00      0.98      1083\n",
            "\n",
            "    accuracy                           0.97      1375\n",
            "   macro avg       0.98      0.94      0.96      1375\n",
            "weighted avg       0.97      0.97      0.97      1375\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:52:32.453987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:52:32.476002: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:52:32.482201: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:52:32.498093: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:52:33.662935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:52:35 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:52:35 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-52-35_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:52:36,105 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:52:36,108 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:52:36,320 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:52:36,321 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:52:36,322 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:52:36,322 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:52:36,322 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:52:36,322 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:52:36,322 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:52:36,322 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:52:36,323 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:52:36,605 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:52:36,679 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:52:36,679 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:52:36 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:52:37 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:52:37,838 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:52:37,839 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:52:38,691 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:52:38,692 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:52:38,692 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:52:38,692 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:52:38,692 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:52:38,692 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:52:38,692 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:52:38,692 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:52:38,692 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:35<04:36,  2.68it/s][INFO|trainer.py:3548] 2024-08-15 14:53:14,574 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:53:14,575 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:53:15,473 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:53:16,809 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:45,  2.84it/s][INFO|trainer.py:3548] 2024-08-15 14:53:52,052 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:53:52,054 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:53:52,956 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:53:54,301 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:50<03:09,  2.85it/s][INFO|trainer.py:3548] 2024-08-15 14:54:28,898 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:54:28,899 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:54:29,786 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:54:31,074 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:27<02:18,  3.17it/s][INFO|trainer.py:3548] 2024-08-15 14:55:06,188 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:55:06,189 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:55:07,086 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:55:08,411 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0281, 'grad_norm': 0.010880103334784508, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:04<02:00,  2.81it/s][INFO|trainer.py:3548] 2024-08-15 14:55:43,483 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:55:43,484 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:55:44,325 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:55:45,604 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:41<01:25,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 14:56:20,466 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:56:20,467 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:56:21,369 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:56:22,713 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:18<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 14:56:57,686 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:56:57,687 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:56:58,592 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:57:00,098 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [04:56<00:12,  3.08it/s][INFO|trainer.py:3548] 2024-08-15 14:57:34,935 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:57:34,936 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:57:36,146 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:12<00:00,  3.34it/s][INFO|trainer.py:3548] 2024-08-15 14:57:51,486 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:57:51,488 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:57:52,691 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 14:57:54,285 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 315.5923, 'train_samples_per_second': 41.319, 'train_steps_per_second': 2.662, 'train_loss': 0.016797921970664036, 'epoch': 40.0}\n",
            "100% 840/840 [05:15<00:00,  2.66it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 14:57:54,287 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:57:54,288 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:57:55,367 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 14:57:55,369 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 14:57:55,369 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - tokens: [CLS] realizar un diagnóstico de la seguridad informa ##tica , utilizando la metodología de anal ##isis de vulnerabilidad ##es para determinar el estado en el cual se encuentra la red en el edificio del banco nacional para proponer posibles contra ##medi ##das y asi prevenir la aparición de vulnerabilidad ##es de alto riesgo y minimizar las mismas utilizando las técnicas de port scan ##ning , net ##w ##ork scan ##ning y vulner ##abil ##ity scan ##ning [SEP]\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_ids: 4 4267 1044 11413 1009 1032 1955 5044 1498 1019 7553 1032 14116 1009 6634 3838 1009 14920 1018 1097 5679 1039 1520 1035 1039 1596 1057 2562 1032 2946 1035 1039 4091 1081 4009 1954 1097 13279 6158 1532 8569 1688 1040 3840 7639 1032 8907 1009 14920 1018 1009 2690 4210 1040 25675 1085 6517 7553 1085 5967 1009 13670 25730 8930 1019 12642 1004 3202 25730 8930 1040 6541 6121 5120 25730 8930 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 -100 -100 2 -100 2 2 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - tokens: [CLS] desarrollar un sistema w ##eb para apoyo en la gestión pastoral y rescate de los valores de la familia para la parroquia san josé obrero , aplicando tecnologías de punta que permitan optimizar el manejo de información y como herramienta de toma de decisión [SEP]\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_ids: 4 5201 1044 2074 1005 3686 1097 2549 1035 1032 3321 23543 1040 9977 1009 1067 5658 1009 1032 2067 1097 1032 11029 1490 3995 16511 1019 14806 6190 1009 8033 1041 11603 28534 1039 10223 1009 1926 1040 1151 9825 1009 2912 1009 2442 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - label_ids: -100 0 1 1 1 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - tokens: [CLS] implementar un sistema w ##eb utilizando tecnología ph ##p y estándares h ##tm ##l ##5 y cs ##s ##3 para el control y monitoreo del impacto ambiental que generan las operaciones y actividades administrativas militares en el comando conjunto de las fuerzas armadas del ecuador . [SEP]\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_ids: 4 19118 1044 2074 1005 3686 7553 3925 4398 30968 1040 14642 1042 14942 30962 31001 1040 15826 30958 31000 1097 1039 2512 1040 24624 1081 6501 8127 1041 21133 1085 3882 1040 2343 9999 5117 1035 1039 11764 3877 1009 1085 3604 9422 1081 8225 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - label_ids: -100 0 1 1 1 -100 2 2 2 -100 2 2 2 -100 -100 -100 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - tokens: [CLS] diseñar e implementar una nube privada bajo el modelo de infraestructura como servicio utilizando herramientas microsoft en la empresa business it para optimizar el uso de recursos . [SEP]\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_ids: 4 18043 1006 19118 1091 14882 6709 2182 1039 4209 1009 7426 1151 2809 7553 8226 18646 1035 1032 3312 22212 6648 1097 28534 1039 2889 1009 2640 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - tokens: [CLS] implementar servicios de red como son : servicio de correo , fire ##w ##all , prox ##y , detección de intruso ##s y escaneo de vulnerabilidad ##es utilizando herramientas de soft ##w ##are libre para mantener la confidencial ##idad , integridad y disponibilidad de la información . [SEP]\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_ids: 4 19118 2316 1009 2946 1151 1318 995 2809 1009 6523 1019 19176 1004 2215 1019 29525 30976 1019 13501 1009 28947 30958 1040 27582 1009 14920 1018 7553 8226 1009 7193 1004 3992 2849 1097 3296 1032 12187 1133 1019 10034 1040 10207 1009 1032 1926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - label_ids: -100 0 1 1 1 2 2 2 2 2 2 2 2 -100 -100 2 2 -100 2 2 2 2 -100 2 2 2 2 -100 2 2 2 2 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:57:55 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 14:57:55,479 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 14:57:55,480 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 14:57:55,480 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 14.79it/s]\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_loss = 0.17739981412887573\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_accuracy_score = 0.969187675070028\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_precision = 0.675\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_recall = 0.75\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_f1 = 0.7105263157894738\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_runtime = 0.419\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_samples_per_second = 85.91\n",
            "08/15/2024 14:57:55 - INFO - __main__ -   test_steps_per_second = 11.932\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.969187675070028 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold6\n",
            "\n",
            "test_f1 0.7105263157894738 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold6\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       1.00      1.00      1.00        35\n",
            "       I-QUE       0.90      0.88      0.89       198\n",
            "           O       0.98      0.98      0.98      1162\n",
            "\n",
            "    accuracy                           0.97      1395\n",
            "   macro avg       0.96      0.96      0.96      1395\n",
            "weighted avg       0.97      0.97      0.97      1395\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 14:58:12.746917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 14:58:12.767188: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 14:58:12.773749: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 14:58:12.788754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 14:58:14.000712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 14:58:16 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 14:58:16 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_14-58-16_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:58:16,527 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:58:16,530 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:58:16,722 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:58:16,723 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:58:16,723 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:58:16,724 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:58:16,724 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:58:16,724 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 14:58:16,724 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 14:58:16,724 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 14:58:16,725 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 14:58:17,012 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 14:58:17,098 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 14:58:17,099 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 14:58:17 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:58:18,345 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 14:58:18,345 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 14:58:19,249 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 14:58:19,250 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 14:58:19,250 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 14:58:19,250 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 14:58:19,250 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 14:58:19,250 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 14:58:19,250 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 14:58:19,250 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 14:58:19,250 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:35<04:31,  2.73it/s][INFO|trainer.py:3548] 2024-08-15 14:58:54,808 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:58:54,809 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:58:55,722 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:58:57,236 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:46,  2.82it/s][INFO|trainer.py:3548] 2024-08-15 14:59:32,632 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 14:59:32,633 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 14:59:33,526 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 14:59:34,843 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:50<03:08,  2.87it/s][INFO|trainer.py:3548] 2024-08-15 15:00:09,376 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:00:09,378 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:00:10,271 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:00:11,627 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:27<02:18,  3.17it/s][INFO|trainer.py:3548] 2024-08-15 15:00:46,843 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:00:46,844 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:00:47,727 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:00:49,055 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0274, 'grad_norm': 0.005834408104419708, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:04<02:01,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 15:01:24,234 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:01:24,235 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:01:25,126 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:01:26,496 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:42<01:25,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 15:02:01,364 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:02:01,366 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:02:02,274 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:02:03,628 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:19<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 15:02:38,534 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:02:38,535 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:02:39,425 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:02:40,848 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [04:58<00:13,  3.04it/s][INFO|trainer.py:3548] 2024-08-15 15:03:18,155 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:03:18,156 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:03:19,370 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:16<00:00,  3.35it/s][INFO|trainer.py:3548] 2024-08-15 15:03:36,153 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:03:36,154 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:03:37,372 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 15:03:38,868 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 319.6181, 'train_samples_per_second': 40.799, 'train_steps_per_second': 2.628, 'train_loss': 0.016463555058553105, 'epoch': 40.0}\n",
            "100% 840/840 [05:19<00:00,  2.63it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 15:03:38,870 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:03:38,872 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:03:39,861 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 15:03:39,863 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 15:03:39,863 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - tokens: [CLS] desarrollar un videojuego educativo 2 ##d para plataformas w ##eb con el motor de juegos h ##tm ##l ##5 , utilizando la metodología ooh ##d ##m para niños entre ##los 7 y 11 años de edad [SEP]\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_ids: 4 5201 1044 16896 12086 1129 30963 1097 16212 1005 3686 1048 1039 5516 1009 4473 1042 14942 30962 31001 1019 7553 1032 14116 17383 30963 30967 1097 2145 1341 1266 999 1040 2116 1469 1009 3047 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 -100 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 2 2 2 2 2 -100 -100 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - tokens: [CLS] analizar , diseñar e implan ##tar un sistema w ##eb para la gestión del proceso de titu ##lación para las carreras de posgrado para llevar un mejor control y agil ##iza , mediante la utiliza ##cion de la plataforma java enterprise edi ##tion je ##e ##6 w ##eb aplicando la metodología sc ##rum [SEP]\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_ids: 4 10190 1019 18043 1006 11552 1148 1044 2074 1005 3686 1097 1032 3321 1081 2621 1009 3843 1726 1097 1085 8962 1009 29445 1097 2860 1044 1544 2512 1040 26273 3464 1019 2811 1032 6174 1105 1009 1032 7688 25701 17248 2240 2728 2106 30955 1000 1005 3686 14806 1032 14116 13233 9606 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 -100 1 1 1 -100 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 -100 2 2 2 2 2 2 -100 2 -100 -100 2 -100 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - tokens: [CLS] utilizar la técnica hack ##ing de pass ##w ##ord crack ##ing mediante el uso de herramientas para encontrar las vulnerabilidad ##es en los sistemas operativos w ##indo ##w ##s y recuperar la contraseña de una cuenta de usuario de la empresa industrial sa de cv [SEP]\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_ids: 4 4917 1032 4274 24129 1623 1009 27211 1004 1809 24095 1623 2811 1039 2889 1009 8226 1097 2229 1085 14920 1018 1035 1067 3751 17071 1005 8810 1004 30958 1040 7297 1032 17817 1009 1091 1946 1009 8563 1009 1032 3312 5822 1782 1009 17995 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - label_ids: -100 0 1 1 1 -100 1 1 -100 -100 1 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - tokens: [CLS] realizar un análisis técnico para la migración de las tic ##s convencionales a los servicios de cloud comput ##ing en las pequeñas y medianas empresas , atra ##vé ##s de la evaluación de las tic ##s convencionales compar ##ándolas con la tecnología de cloud comput ##ing para establecer las ventajas y desventajas de su implementación en la empresa di ##por sa de cv [SEP]\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_ids: 4 4267 1044 4089 6476 1097 1032 11094 1009 1085 11765 30958 13904 1012 1067 2316 1009 29698 12390 1623 1035 1085 4915 1040 16275 3171 1019 2559 25463 30958 1009 1032 4150 1009 1085 11765 30958 13904 2780 21224 1048 1032 3925 1009 29698 12390 1623 1097 4163 1085 9463 1040 28958 1009 1069 13811 1035 1032 3312 1111 1439 1782 1009 17995 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - label_ids: -100 0 1 1 1 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - tokens: [CLS] desarrollar e implementar un sistema gesto ##r de incidentes en el área de ps & i - g ##do para la empresa x ##ero ##x s . a , ajustan ##do sus procesos a las mejores prácticas de gestión de servicios que propone el marco de trabajo it ##il . utilizando como metodología de desarrollo de soft ##w ##are a u ##w ##e um ##l , mejorando de manera óptima la gestión del servicio del área . [SEP]\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_ids: 4 5201 1006 19118 1044 2074 15415 30960 1009 14107 1035 1039 3967 1009 3781 971 1121 1139 1071 1050 1097 1032 3312 2352 1213 30991 1015 1008 1012 1019 30598 1050 1233 5676 1012 1085 3858 4636 1009 3321 1009 2316 1041 7906 1039 2927 1009 1608 6648 1123 1008 7553 1151 14116 1009 1766 1009 7193 1004 3992 1012 1482 1004 30955 5856 30962 1019 14523 1009 2160 22751 1032 3321 1081 2809 1081 3967 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 -100 1 1 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 -100 -100 2 -100 -100 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 -100 2 2 -100 -100 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:03:39 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 15:03:39,968 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 15:03:39,968 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 15:03:39,968 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 14.73it/s]\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_loss = 0.23951366543769836\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_accuracy_score = 0.9707426856714179\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_precision = 0.7435897435897436\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_recall = 0.8055555555555556\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_f1 = 0.7733333333333334\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_runtime = 0.4206\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_samples_per_second = 85.589\n",
            "08/15/2024 15:03:40 - INFO - __main__ -   test_steps_per_second = 11.887\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9707426856714179 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold7\n",
            "\n",
            "test_f1 0.7733333333333334 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold7\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       1.00      1.00      1.00        35\n",
            "       I-QUE       0.90      0.93      0.92       230\n",
            "           O       0.98      0.98      0.98      1042\n",
            "\n",
            "    accuracy                           0.97      1307\n",
            "   macro avg       0.96      0.97      0.97      1307\n",
            "weighted avg       0.97      0.97      0.97      1307\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 15:03:57.337019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 15:03:57.357718: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 15:03:57.363730: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 15:03:57.378794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 15:03:58.580532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 15:04:00 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 15:04:00 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_15-04-00_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 15:04:01,071 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 15:04:01,075 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 15:04:01,269 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 15:04:01,270 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:04:01,270 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:04:01,270 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:04:01,270 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:04:01,270 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:04:01,270 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 15:04:01,271 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 15:04:01,271 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 15:04:01,553 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 15:04:01,634 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 15:04:01,634 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - Writing example 0 of 326\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:04:01 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:04:02 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 15:04:02,901 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 15:04:02,901 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 15:04:03,809 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 15:04:03,809 >>   Num examples = 326\n",
            "[INFO|trainer.py:2162] 2024-08-15 15:04:03,809 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 15:04:03,809 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 15:04:03,809 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 15:04:03,809 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 15:04:03,809 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 15:04:03,809 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 15:04:03,810 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:36<04:36,  2.68it/s][INFO|trainer.py:3548] 2024-08-15 15:04:39,896 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:04:39,897 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:04:40,806 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:04:42,208 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:14<03:46,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 15:05:17,859 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:05:17,860 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:05:18,768 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:05:20,247 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:51<03:10,  2.84it/s][INFO|trainer.py:3548] 2024-08-15 15:05:55,035 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:05:55,036 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:05:55,944 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:05:57,291 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:28<02:18,  3.17it/s][INFO|trainer.py:3548] 2024-08-15 15:06:32,343 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:06:32,344 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:06:33,254 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:06:34,639 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0266, 'grad_norm': 0.03653125837445259, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:05<02:01,  2.79it/s][INFO|trainer.py:3548] 2024-08-15 15:07:09,783 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:07:09,784 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:07:10,643 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:07:12,021 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:44<01:25,  2.80it/s][INFO|trainer.py:3548] 2024-08-15 15:07:47,894 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:07:47,895 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:07:48,682 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:07:50,061 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:23<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 15:08:27,298 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:08:27,300 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:08:28,085 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:08:29,389 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [05:00<00:13,  3.07it/s][INFO|trainer.py:3548] 2024-08-15 15:09:04,202 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:09:04,203 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:09:05,298 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:16<00:00,  3.35it/s][INFO|trainer.py:3548] 2024-08-15 15:09:20,640 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:09:20,641 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:09:21,777 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 15:09:23,259 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 319.4495, 'train_samples_per_second': 40.82, 'train_steps_per_second': 2.63, 'train_loss': 0.015957300835067318, 'epoch': 40.0}\n",
            "100% 840/840 [05:19<00:00,  2.63it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 15:09:23,261 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:09:23,262 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:09:24,166 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 15:09:24,168 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 15:09:24,168 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - tokens: [CLS] realizar el análisis , diseño e implementación de un sistema de gestión de donaciones y voluntaria ##do para la [UNK] fundación jóvenes contra el cáncer [UNK] , utilizando la arquitectura je ##e ##6 sobre un servidor j ##bos ##s as 7 aplicando la metodología extrem ##e program ##ming . [SEP]\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_ids: 4 4267 1039 4089 1019 5083 1006 13811 1009 1044 2074 1009 3321 1009 17707 1040 16302 1050 1097 1032 3 5893 3780 1532 1039 5939 3 1019 7553 1032 8524 2106 30955 1000 1246 1044 11944 1117 6578 30958 1146 999 14806 1032 14116 7370 30955 12367 13641 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 -100 2 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - tokens: [CLS] construir e implementar un sistema de información para la administración integral de pacientes , doctores y servicios de la clínica dental barrera , que ofrezca a los usuarios soluciones para optimizar procesos , utilizando metodologías de desarrollo á ##gil ##es [SEP]\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_ids: 4 6039 1006 19118 1044 2074 1009 1926 1097 1032 3764 10365 1009 6549 1019 14984 1040 2316 1009 1032 11012 22009 14993 1019 1041 27282 1012 1067 6637 7684 1097 28534 5676 1019 7553 22967 1009 1766 1592 17070 1018 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - tokens: [CLS] desarrollar un sistema w ##eb para la empresa ltd ##a mediante la investigación , aplicación de tecnologías actuales , herramientas de soft ##w ##are libre y siguiendo una metodología de desarrollo acorde a los requerimientos de este proyecto , para gestionar archivos digitales , controlar y administrar los movimientos de materiales de cualquier bodega y llevar contro de la información contable [SEP]\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_ids: 4 5201 1044 2074 1005 3686 1097 1032 3312 20703 30956 2811 1032 2764 1019 2407 1009 6190 6966 1019 8226 1009 7193 1004 3992 2849 1040 7165 1091 14116 1009 1766 17407 1012 1067 23216 1009 1277 2269 1019 1097 17047 6350 14095 1019 6032 1040 14922 1067 7224 1009 5389 1009 2048 17393 1040 2860 2091 1009 1032 1926 20751 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - tokens: [CLS] construir e implementar un sistema de información para la administración integral de pacientes , doctores y servicios de la clínica dental barrera , que ofrezca a los usuarios soluciones para optimizar procesos , utilizando metodologías de desarrollo á ##gil ##es . [SEP]\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_ids: 4 6039 1006 19118 1044 2074 1009 1926 1097 1032 3764 10365 1009 6549 1019 14984 1040 2316 1009 1032 11012 22009 14993 1019 1041 27282 1012 1067 6637 7684 1097 28534 5676 1019 7553 22967 1009 1766 1592 17070 1018 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - tokens: [CLS] desarrollar el w ##eb site corporativo para la gestion y validación de documentos de la organización una ##tec aplicando certificados de firma electron ##ica [SEP]\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_ids: 4 5201 1039 1005 3686 28756 29334 1097 1032 10847 1040 29687 1009 4185 1009 1032 2681 1091 1962 14806 14324 1009 6196 27087 1172 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - label_ids: -100 0 1 1 -100 1 1 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:24 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 15:09:24,277 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 15:09:24,277 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 15:09:24,277 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 15.14it/s]\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_loss = 0.13885577023029327\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_accuracy_score = 0.9792709077912795\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_precision = 0.7297297297297297\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_recall = 0.75\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_f1 = 0.7397260273972601\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_runtime = 0.4112\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_samples_per_second = 87.545\n",
            "08/15/2024 15:09:24 - INFO - __main__ -   test_steps_per_second = 12.159\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9792709077912795 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold8\n",
            "\n",
            "test_f1 0.7397260273972601 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold8\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       1.00      1.00      1.00        35\n",
            "       I-QUE       0.95      0.93      0.94       244\n",
            "           O       0.99      0.99      0.99      1105\n",
            "\n",
            "    accuracy                           0.98      1384\n",
            "   macro avg       0.98      0.97      0.98      1384\n",
            "weighted avg       0.98      0.98      0.98      1384\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-08-15 15:09:41.313028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 15:09:41.333052: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 15:09:41.339099: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 15:09:41.353703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 15:09:42.500813: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 15:09:44 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 15:09:44 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=bert-base-ml-ner/runs/Aug15_15-09-44_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=bert-base-ml-ner,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=bert-base-ml-ner,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 15:09:44,893 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 15:09:44,897 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 15:09:45,091 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 15:09:45,092 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:09:45,093 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:09:45,093 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:09:45,093 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:09:45,093 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2269] 2024-08-15 15:09:45,093 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/tokenizer.json\n",
            "[INFO|configuration_utils.py:733] 2024-08-15 15:09:45,093 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 15:09:45,094 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "[INFO|modeling_utils.py:3657] 2024-08-15 15:09:45,376 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--dccuchile--bert-base-spanish-wwm-uncased/snapshots/d1c9c4565c9d6731e57ed7f027b802697bad861e/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:4479] 2024-08-15 15:09:45,456 >> Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:4491] 2024-08-15 15:09:45,456 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - Writing example 0 of 327\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - guid: train-1\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - tokens: [CLS] uno de los objetivos más importantes del proyecto , fue crear un conjunto de rutina ##s independientes del hard ##w ##are , que se auto configurar ##an al tiempo de ejecución de manera transparente al programado ##r sin que por ello se perdi ##era la sencil ##lez de programa ##ci ##6 ##n o el alcance y efectividad de la unidad . cabe mencionar que siempre se tuvo en mente el tratar de proporcionar un ambiente agradable como resultado del uso de las rutina ##s de la unidad , para lo cual se diseñar ##on las presentaciones tomando el mayor cuidado posible , haciendo siempre consultas a diferentes personas a las cuales les estoy agradecido por su valiosa participación . [SEP]\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_ids: 4 1614 1009 1067 3501 1186 3521 1081 2269 1019 1247 3959 1044 3877 1009 14619 30958 8751 1081 11722 1004 3992 1019 1041 1057 2183 26175 1029 1074 1526 1009 4242 1009 2160 14797 1074 19313 30960 1320 1041 1076 2601 1057 23696 1178 1032 4378 7678 1009 1952 1024 1000 30959 1068 1039 5909 1040 19651 1009 1032 4205 1008 6324 9691 1041 1772 1057 2839 1035 4260 1039 4221 1009 6776 1044 3508 6495 1151 3776 1081 2889 1009 1085 14619 30958 1009 1032 4205 1019 1097 1086 1596 1057 18043 1022 1085 14211 5794 1039 1736 3234 2368 1019 2194 1772 6412 1012 3055 1845 1012 1085 3523 1777 1435 15793 1076 1069 16598 3374 1008 5 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 -100 1 1 1 -100 -100 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 -100 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - guid: train-2\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - tokens: [CLS] en el presente trabajo se pretende : presentar una breve introducción a los protocolos de en ##ru ##tamiento identificar las características deseable ##s en los protocolos de en ##ru ##tamiento realizar un análisis descrip ##tivo de los protocolos más importantes , así como las razones de su éxito mediante una simulación en un programa de entrenamiento el mecanismo que se lleva a cabo para configurar en un en ##ru ##tador un protocolo de en ##ru ##tamiento simple , como lo es el protocolo [SEP]\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_ids: 4 1035 1039 2807 1608 1057 10185 995 3729 1091 7178 6760 1012 1067 11902 1009 1035 1366 10765 8849 1085 5616 27280 30958 1035 1067 11902 1009 1035 1366 10765 4267 1044 4089 13429 1483 1009 1067 11902 1186 3521 1019 1337 1151 1085 5367 1009 1069 3613 2811 1091 22327 1035 1044 1952 1009 8222 1039 6267 1041 1057 3664 1012 3170 1097 26175 1035 1044 1035 1366 4633 1044 4584 1009 1035 1366 10765 2940 1019 1151 1086 1028 1039 4584 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 -100 2 2 2 2 2 -100 -100 2 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - guid: train-3\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - tokens: [CLS] nuestro objetivo principal es crear claus ##ulas multi ##valor ##es que mejore ##n la expres ##ividad del lenguaje en il ##p , con ello se espera que los algoritmo ##s il ##p constru ##yan hipo ##tesis con menos claus ##ulas y por lo tanto mas facil ##es de interpretar , utilizando los algoritmo ##s de lenguaje il ##p [SEP]\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_ids: 4 2045 3073 3025 1028 3959 8933 4955 4284 27882 1018 1041 25635 30959 1032 2749 18582 1081 8023 1035 4070 30968 1019 1048 2601 1057 2216 1041 1067 23497 30958 4070 30968 3054 3516 8484 7703 1048 1885 8933 4955 1040 1076 1086 1850 2062 3476 1018 1009 13146 1019 7553 1067 23497 30958 1009 8023 4070 30968 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - label_ids: -100 2 2 2 2 0 1 -100 1 -100 -100 1 1 -100 1 1 -100 1 1 1 1 -100 2 2 2 2 2 2 2 2 -100 2 -100 2 -100 2 -100 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - guid: train-4\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - tokens: [CLS] observar la evolución del comportamiento de los nodos de un sistema p ##2 ##p , cuando reciben incentivos por su coopera ##cion ( duplic ##ar ) , para lo cual model ##amos la situación estratégica de los nodos ( duplic ##ar , no duplic ##ar ) y el sistema con un juego , utilizando mecanismos que compens ##en la cooperación de los nodos . [SEP]\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_ids: 4 9069 1032 6066 1081 7060 1009 1067 30926 1009 1044 2074 1011 30989 30968 1019 1351 9868 17436 1076 1069 9356 1105 1147 12452 1020 1135 1019 1097 1086 1596 26385 1209 1032 2471 12241 1009 1067 30926 1147 12452 1020 1019 1054 12452 1020 1135 1040 1039 2074 1048 1044 2934 1019 7553 5719 1041 7840 1017 1032 2730 1009 1067 30926 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 1 1 1 -100 -100 2 2 2 2 2 2 2 -100 2 2 -100 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 2 -100 2 2 2 -100 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - guid: train-5\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - tokens: [CLS] el objetivo al elaborar esta aplicación es el introducir ##se al desarrollo de soft ##w ##are , así como conocer y aprender a programar en el ambiente orientado a objetos en este caso en visual c + + utilizando un lenguaje para computación móvil . [SEP]\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_ids: 4 1039 3073 1074 8445 1149 2407 1028 1039 10219 1182 1074 1766 1009 7193 1004 3992 1019 1337 1151 3266 1040 5331 1012 26817 1035 1039 3508 19456 1012 6997 1035 1277 2053 1035 11606 1013 967 967 7553 1044 8023 1097 25466 6803 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:09:45 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 1 -100 1 1 1 1 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:09:46 - INFO - utils_ner - Saving features into cached file ./cached_train_BertTokenizer_128\n",
            "[WARNING|training_args.py:2072] 2024-08-15 15:09:46,643 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1907: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[WARNING|training_args.py:2072] 2024-08-15 15:09:46,643 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:2160] 2024-08-15 15:09:47,540 >> ***** Running training *****\n",
            "[INFO|trainer.py:2161] 2024-08-15 15:09:47,540 >>   Num examples = 327\n",
            "[INFO|trainer.py:2162] 2024-08-15 15:09:47,540 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:2163] 2024-08-15 15:09:47,540 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:2165] 2024-08-15 15:09:47,540 >>   Training with DataParallel so batch size has been adjusted to: 16\n",
            "[INFO|trainer.py:2166] 2024-08-15 15:09:47,541 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2167] 2024-08-15 15:09:47,541 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2168] 2024-08-15 15:09:47,541 >>   Total optimization steps = 840\n",
            "[INFO|trainer.py:2169] 2024-08-15 15:09:47,541 >>   Number of trainable parameters = 109,262,595\n",
            " 12% 100/840 [00:35<04:34,  2.70it/s][INFO|trainer.py:3548] 2024-08-15 15:10:23,259 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-100\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:10:23,260 >> Configuration saved in bert-base-ml-ner/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:10:24,183 >> Model weights saved in bert-base-ml-ner/checkpoint-100/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:10:25,614 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-100] due to args.save_total_limit\n",
            " 24% 200/840 [01:13<03:46,  2.82it/s][INFO|trainer.py:3548] 2024-08-15 15:11:01,007 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-200\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:11:01,009 >> Configuration saved in bert-base-ml-ner/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:11:01,896 >> Model weights saved in bert-base-ml-ner/checkpoint-200/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:11:03,292 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-200] due to args.save_total_limit\n",
            " 36% 300/840 [01:50<03:09,  2.85it/s][INFO|trainer.py:3548] 2024-08-15 15:11:38,012 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-300\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:11:38,013 >> Configuration saved in bert-base-ml-ner/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:11:38,908 >> Model weights saved in bert-base-ml-ner/checkpoint-300/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:11:40,257 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-300] due to args.save_total_limit\n",
            " 48% 400/840 [02:27<02:20,  3.12it/s][INFO|trainer.py:3548] 2024-08-15 15:12:15,435 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-400\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:12:15,436 >> Configuration saved in bert-base-ml-ner/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:12:16,323 >> Model weights saved in bert-base-ml-ner/checkpoint-400/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:12:17,643 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.0296, 'grad_norm': 0.0028261165134608746, 'learning_rate': 1.2142857142857144e-05, 'epoch': 23.81}\n",
            " 60% 500/840 [03:05<02:00,  2.81it/s][INFO|trainer.py:3548] 2024-08-15 15:12:52,808 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:12:52,809 >> Configuration saved in bert-base-ml-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:12:53,614 >> Model weights saved in bert-base-ml-ner/checkpoint-500/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:12:54,942 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-500] due to args.save_total_limit\n",
            " 71% 600/840 [03:42<01:26,  2.79it/s][INFO|trainer.py:3548] 2024-08-15 15:13:29,913 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-600\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:13:29,914 >> Configuration saved in bert-base-ml-ner/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:13:30,779 >> Model weights saved in bert-base-ml-ner/checkpoint-600/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:13:32,107 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-600] due to args.save_total_limit\n",
            " 83% 700/840 [04:19<00:49,  2.83it/s][INFO|trainer.py:3548] 2024-08-15 15:14:07,219 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-700\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:14:07,220 >> Configuration saved in bert-base-ml-ner/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:14:08,091 >> Model weights saved in bert-base-ml-ner/checkpoint-700/model.safetensors\n",
            "[INFO|trainer.py:3640] 2024-08-15 15:14:09,427 >> Deleting older checkpoint [bert-base-ml-ner/checkpoint-700] due to args.save_total_limit\n",
            " 95% 800/840 [04:56<00:13,  3.03it/s][INFO|trainer.py:3548] 2024-08-15 15:14:44,477 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-800\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:14:44,479 >> Configuration saved in bert-base-ml-ner/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:14:45,631 >> Model weights saved in bert-base-ml-ner/checkpoint-800/model.safetensors\n",
            "100% 840/840 [05:13<00:00,  3.27it/s][INFO|trainer.py:3548] 2024-08-15 15:15:01,024 >> Saving model checkpoint to bert-base-ml-ner/checkpoint-840\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:15:01,025 >> Configuration saved in bert-base-ml-ner/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:15:02,183 >> Model weights saved in bert-base-ml-ner/checkpoint-840/model.safetensors\n",
            "[INFO|trainer.py:2420] 2024-08-15 15:15:03,706 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 316.1651, 'train_samples_per_second': 41.371, 'train_steps_per_second': 2.657, 'train_loss': 0.017705212205293634, 'epoch': 40.0}\n",
            "100% 840/840 [05:16<00:00,  2.66it/s]\n",
            "[INFO|trainer.py:3548] 2024-08-15 15:15:03,708 >> Saving model checkpoint to bert-base-ml-ner\n",
            "[INFO|configuration_utils.py:472] 2024-08-15 15:15:03,710 >> Configuration saved in bert-base-ml-ner/config.json\n",
            "[INFO|modeling_utils.py:2778] 2024-08-15 15:15:04,835 >> Model weights saved in bert-base-ml-ner/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2684] 2024-08-15 15:15:04,838 >> tokenizer config file saved in bert-base-ml-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2693] 2024-08-15 15:15:04,838 >> Special tokens file saved in bert-base-ml-ner/special_tokens_map.json\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - Creating features from dataset file at ./\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - Writing example 0 of 36\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - tokens: [CLS] estudiar la problemática de la detección del pla ##gio desde el punto de vista estadístico con el afán de observar cuáles son las ventajas y carencia ##s de los métodos existentes hasta ahora . [SEP]\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_ids: 4 6661 1032 19970 1009 1032 13501 1081 1786 6147 1540 1039 2318 1009 3064 21510 1048 1039 27671 1009 9069 8299 1318 1085 9463 1040 23126 30958 1009 1067 5649 6569 1506 1388 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 1 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - guid: test-2\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - tokens: [CLS] implan ##tar un modelo de evaluación a través de variables ling ##ui ##st ##icas para medir la productividad de los investigadores del instituto y generar una base de conocimiento dinámica para la asignación presupues ##tal a los proyectos de investigación . [SEP]\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_ids: 4 11552 1148 1044 4209 1009 4150 1012 2589 1009 14730 9686 14818 8689 1800 1097 12358 1032 12955 1009 1067 9534 1081 4367 1040 11270 1091 2664 1009 4764 13230 1097 1032 10926 6694 1278 1012 1067 3355 1009 2764 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - label_ids: -100 0 -100 1 1 1 1 2 2 2 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - guid: test-3\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - tokens: [CLS] realizar el análisis de los certificados digitales y análisis , diseño e implementación de firmas digitales como medida de seguridad para la auten ##tica ##ción de documentos firmados por las diferentes autoridades , para el tráfico en las redes de correo electrónico . [SEP]\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_ids: 4 4267 1039 4089 1009 1067 14324 14095 1040 4089 1019 5083 1006 13811 1009 15157 14095 1151 3626 1009 1955 1097 1032 18147 1498 1065 1009 4185 26657 1076 1085 3055 3841 1019 1097 1039 5372 1035 1085 5817 1009 6523 7523 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - guid: test-4\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - tokens: [CLS] implementar una solución anti spa ##m para la empresa ecua ##on ##line , mediante uso de filtro de contenido y distintas soluciones encaminadas a la eliminación del correo basura en la red de la empresa . [SEP]\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_ids: 4 19118 1091 4667 2180 11119 30967 1097 1032 3312 12674 1022 10666 1019 2811 2889 1009 21135 1009 5271 1040 5696 7684 13299 1012 1032 6301 1081 6523 6351 1035 1032 2946 1009 1032 3312 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 -100 2 2 2 2 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - guid: test-5\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - tokens: [CLS] desarrollar el sistema de gestión de va ##deme ##cum ##s y módulos de control de usuarios y clientes , para la empresa edi ##far ##m & cí ##a utilizando soft ##w ##are libre y priva ##tivo . [SEP]\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_ids: 4 5201 1039 2074 1009 3321 1009 1453 24087 26558 30958 1040 19851 1009 2512 1009 6637 1040 5184 1019 1097 1032 3312 2240 11021 30967 971 10881 30956 7553 7193 1004 3992 2849 1040 8988 1483 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - label_ids: -100 0 1 1 1 1 2 2 -100 -100 -100 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 -100 2 2 -100 2 2 -100 -100 2 2 2 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 15:15:04 - INFO - utils_ner - Saving features into cached file ./cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 15:15:04,953 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 15:15:04,953 >>   Num examples = 36\n",
            "[INFO|trainer.py:3869] 2024-08-15 15:15:04,953 >>   Batch size = 8\n",
            "100% 5/5 [00:00<00:00, 14.94it/s]\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_loss = 0.24587160348892212\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_accuracy_score = 0.9730094466936572\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_precision = 0.7567567567567568\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_recall = 0.7777777777777778\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_f1 = 0.7671232876712328\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_runtime = 0.4157\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_samples_per_second = 86.601\n",
            "08/15/2024 15:15:05 - INFO - __main__ -   test_steps_per_second = 12.028\n",
            "/bin/bash: line 2: .json: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "/bin/bash: line 2: .txt: command not found\n",
            "test_accuracy_score 0.9730094466936572 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold9\n",
            "\n",
            "test_f1 0.7671232876712328 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold9\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "RESULTADOS FOLDER 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-QUE       1.00      1.00      1.00        35\n",
            "       I-QUE       0.82      1.00      0.90       187\n",
            "           O       1.00      0.97      0.98      1224\n",
            "\n",
            "    accuracy                           0.97      1446\n",
            "   macro avg       0.94      0.99      0.96      1446\n",
            "weighted avg       0.98      0.97      0.97      1446\n",
            "\n",
            "0.7945205479452055 epoch_40_learn_3e-05_batch_16_corpusArgPC_fold4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "#model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "# for i in range(100):\n",
        "#   x = 100 + 11999 + 2000\n",
        "#   current_time = time.time()\n",
        "#   elapsed_time = current_time - start_time\n",
        "\n",
        "\n",
        "\n",
        "# (0.0003, 8) learn y batch\n",
        "#epoch = 10\n",
        "corpus = \"ArgPC\"\n",
        "max_test_f1 = 0\n",
        "max_test_accuracy_score = 0\n",
        "max_parametros = \"\"\n",
        "\n",
        "\n",
        "for k in range( len( parameters ) ) :\n",
        "\n",
        "  sumaF1 = 0\n",
        "  sumaAcc = 0\n",
        "\n",
        "\n",
        "  for fold in range(0,10):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    !rm train.txt\n",
        "    !rm test.txt\n",
        "\n",
        "\n",
        "    # !python3 preprocess.py /content/drive/MyDrive/Exp_Objetivos2021/folders/fold_{fold}_train.txt $MODEL $MAX_LENGTH > train.txt\n",
        "    # !python3 preprocess.py /content/drive/MyDrive/Exp_Objetivos2021/folders/fold_{fold}_test.txt $MODEL $MAX_LENGTH > test.txt\n",
        "\n",
        "    !python3 preprocess.py /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE/fold_{fold}_train.txt $MODEL $MAX_LENGTH > train.txt\n",
        "    !python3 preprocess.py /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE/fold_{fold}_test.txt $MODEL $MAX_LENGTH > test.txt\n",
        "\n",
        "\n",
        "    !cat train.txt  test.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt\n",
        "\n",
        "    #epoch = parameters[k][2]\n",
        "    epoch=40\n",
        "\n",
        "\n",
        "\n",
        "    MAX_LENGTH = 128\n",
        "    MODEL = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
        "    #MODEL = \"chriskhanhtran/spanberta\"\n",
        "    OUTPUT_DIR = \"bert-base-ml-ner\"\n",
        "    BATCH_SIZE = parameters[k][1] #32\n",
        "    NUM_EPOCHS = epoch\n",
        "    SAVE_STEPS = 100\n",
        "    LOGGING_STEPS = 100\n",
        "    SEED = 42\n",
        "    LEARNING_RATE = parameters[k][0]\n",
        "\n",
        "\n",
        "    parametros = f\"epoch_{str(epoch)}_learn_{str(LEARNING_RATE)}_batch_{str(BATCH_SIZE)}_corpus{corpus}_fold{str(fold)}\\n\"\n",
        "\n",
        "    !python3 run_ner.py --data_dir ./ \\\n",
        "    --labels ./labels.txt \\\n",
        "    --model_name_or_path $MODEL \\\n",
        "    --output_dir $OUTPUT_DIR \\\n",
        "    --max_seq_length  $MAX_LENGTH \\\n",
        "    --num_train_epochs $NUM_EPOCHS \\\n",
        "    --per_gpu_train_batch_size $BATCH_SIZE \\\n",
        "    --save_steps $SAVE_STEPS \\\n",
        "    --seed $SEED \\\n",
        "    --do_train \\\n",
        "    --do_predict \\\n",
        "    --overwrite_cache \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_total_limit 2 \\\n",
        "    --learning_rate $LEARNING_RATE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    !cp ./bert-base-ml-ner/config.json  {dir}config_{parametros}.json\n",
        "    !cp ./bert-base-ml-ner/test_predictions.txt   {dir}test_predictions_{parametros}.txt\n",
        "    !cp ./bert-base-ml-ner/test_results.txt   {dir}test_results_{parametros}.txt\n",
        "\n",
        "    archivo_result = \"./bert-base-ml-ner/test_results.txt\"\n",
        "    test_f1_current = 0\n",
        "    test_accuracy_score_current = 0\n",
        "\n",
        "    current_time = time.time()\n",
        "    elapsed_time = current_time - start_time\n",
        "\n",
        "    testsite_array = []\n",
        "    with open(archivo_result) as my_file:\n",
        "        for line in my_file:\n",
        "            testsite_array.append(line.split() )\n",
        "            if line.split()[0] == \"test_f1\":\n",
        "              print(\"test_f1\",line.split()[2],parametros)\n",
        "              test_f1_current = float(line.split()[2])\n",
        "            if line.split()[0] ==  \"test_accuracy_score\":\n",
        "              print(\"test_accuracy_score\",line.split()[2],parametros)\n",
        "              test_accuracy_score_current = float(line.split()[2])\n",
        "\n",
        "    f = open(dir+\"log_exp.txt\", \"a+\")\n",
        "    log_text = f\"{str(test_accuracy_score_current),str(test_f1_current)},{str(epoch)},{str(LEARNING_RATE)},{str(BATCH_SIZE)},{corpus},{str(fold)},time,{str(elapsed_time)}\\n\"\n",
        "    f.write(log_text)\n",
        "    f.close()\n",
        "\n",
        "    # guardo para acumular F1 y acc\n",
        "\n",
        "    sumaAcc += test_accuracy_score_current\n",
        "    sumaF1 += test_f1_current\n",
        "\n",
        "\n",
        "    if max_test_f1 < test_f1_current :\n",
        "      max_test_f1 = test_f1_current\n",
        "      max_parametros = parametros\n",
        "\n",
        "    #**********resultados\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import classification_report\n",
        "    !rm test.txt\n",
        "\n",
        "    # !python3 preprocess.py /content/drive/MyDrive/Exp_Objetivos2021/folders/fold_{fold}_test.txt $MODEL $MAX_LENGTH > test.txt\n",
        "    !python3 preprocess.py /content/drive/MyDrive/ColabNotebooks/BERT/FoldersQUE/fold_{fold}_test.txt $MODEL $MAX_LENGTH > test.txt\n",
        "    !python3 preprocess.py /content/bert-base-ml-ner/test_predictions.txt $MODEL $MAX_LENGTH > prediction.txt\n",
        "\n",
        "    !cat test.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt\n",
        "\n",
        "\n",
        "    y_true = read_examples_from_file(\"test.txt\")[\"labels\"]\n",
        "    y_pred = read_examples_from_file(\"prediction.txt\")[\"labels\"]\n",
        "    print (\"RESULTADOS FOLDER\", fold)\n",
        "    print(classification_report(np.concatenate(y_true), np.concatenate(y_pred)))\n",
        "\n",
        "    #***********resultados\n",
        "\n",
        "\n",
        "  print(max_test_f1,max_parametros)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Results"
      ],
      "metadata": {
        "id": "w3C9e-tKolJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4dVT91CHe0JZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fd063853-fd71-460f-c16d-612419d7129d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/bert-base-ml-ner/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/test_predictions.txt (deflated 70%)\n",
            "  adding: content/bert-base-ml-ner/config.json (deflated 49%)\n",
            "  adding: content/bert-base-ml-ner/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/bert-base-ml-ner/test_results.txt (deflated 43%)\n",
            "  adding: content/bert-base-ml-ner/model.safetensors (deflated 7%)\n",
            "  adding: content/bert-base-ml-ner/vocab.txt (deflated 56%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/config.json (deflated 49%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/model.safetensors (deflated 7%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/optimizer.pt (deflated 27%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/trainer_state.json (deflated 54%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/scheduler.pt (deflated 56%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/training_args.bin (deflated 51%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-840/rng_state.pth (deflated 25%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/config.json (deflated 49%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/model.safetensors (deflated 7%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/optimizer.pt (deflated 27%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/trainer_state.json (deflated 55%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/scheduler.pt (deflated 55%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/training_args.bin (deflated 51%)\n",
            "  adding: content/bert-base-ml-ner/checkpoint-800/rng_state.pth (deflated 25%)\n",
            "  adding: content/bert-base-ml-ner/training_args.bin (deflated 51%)\n",
            "  adding: content/bert-base-ml-ner/special_tokens_map.json (deflated 80%)\n",
            "  adding: content/bert-base-ml-ner/runs/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-41-08_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-41-08_d361184ba2d6/events.out.tfevents.1723732871.d361184ba2d6.14236.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-52-35_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-52-35_d361184ba2d6/events.out.tfevents.1723733558.d361184ba2d6.17416.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_15-09-44_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_15-09-44_d361184ba2d6/events.out.tfevents.1723734587.d361184ba2d6.22037.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-58-16_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-58-16_d361184ba2d6/events.out.tfevents.1723733899.d361184ba2d6.18971.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-29-45_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-29-45_d361184ba2d6/events.out.tfevents.1723732187.d361184ba2d6.11075.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_15-04-00_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_15-04-00_d361184ba2d6/events.out.tfevents.1723734243.d361184ba2d6.20509.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-46-52_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-46-52_d361184ba2d6/events.out.tfevents.1723733215.d361184ba2d6.15834.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-24-04_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-24-04_d361184ba2d6/events.out.tfevents.1723731847.d361184ba2d6.9498.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-35-25_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-35-25_d361184ba2d6/events.out.tfevents.1723732528.d361184ba2d6.12649.0 (deflated 59%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-18-07_d361184ba2d6/ (stored 0%)\n",
            "  adding: content/bert-base-ml-ner/runs/Aug15_14-18-07_d361184ba2d6/events.out.tfevents.1723731513.d361184ba2d6.7837.0 (deflated 59%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/bert-base-ml-ner.zip /content/bert-base-ml-ner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/bert-base-ml-ner.zip.zip\")"
      ],
      "metadata": {
        "id": "r6XlEMgxoxaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests\n"
      ],
      "metadata": {
        "id": "JyK9aAPFtc3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"MODEL\"         $MODEL\n",
        "!echo \"OUTPUT_DIR\"    $OUTPUT_DIR\n",
        "!echo \"MAX_LENGTH\"    $MAX_LENGTH\n",
        "!echo \"NUM_EPOCHS\"    $NUM_EPOCHS\n",
        "!echo \"BATCH_SIZE\"    $BATCH_SIZE\n",
        "!echo \"SAVE_STEPS\"    $SAVE_STEPS\n",
        "!echo \"SEED\"          $SEED\n",
        "!echo \"LEARNING_RATE\" $LEARNING_RATE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "momYdiWDtjaI",
        "outputId": "941c30d8-045f-4bca-ff8f-939a2bebdd79"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL dccuchile/bert-base-spanish-wwm-uncased\n",
            "OUTPUT_DIR bert-base-ml-ner\n",
            "MAX_LENGTH 128\n",
            "NUM_EPOCHS 40\n",
            "BATCH_SIZE 16\n",
            "SAVE_STEPS 100\n",
            "SEED 42\n",
            "LEARNING_RATE 3e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess.py /content/drive/MyDrive/ColabNotebooks/BERT/Tests/obetivo.txt /content/bert-base-ml-ner 128 > /content/drive/MyDrive/ColabNotebooks/BERT/Tests/test.txt"
      ],
      "metadata": {
        "id": "IsMaV05huKDn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/drive/MyDrive/ColabNotebooks/BERT/Tests/test.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV-ANJTEw02E",
        "outputId": "8e18358e-6102-4b11-992a-0c106a243602"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "implementar O\n",
            "un O\n",
            "esquema O\n",
            "de O\n",
            "base O\n",
            "de O\n",
            "datos O\n",
            "que O\n",
            "soporte O\n",
            "seguimiento O\n",
            "semanal O\n",
            "y O\n",
            "listas O\n",
            "de O\n",
            "tareas O\n",
            "kanban O\n",
            ". O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run_ner.py --data_dir /content/drive/MyDrive/ColabNotebooks/BERT/Tests \\\n",
        "    --labels /content/drive/MyDrive/ColabNotebooks/BERT/Tests/labels.txt \\\n",
        "    --model_name_or_path /content/bert-base-ml-ner \\\n",
        "    --output_dir /content/drive/MyDrive/ColabNotebooks/BERT/Tests/results \\\n",
        "    --max_seq_length  128 \\\n",
        "    --num_train_epochs 40 \\\n",
        "    --per_gpu_train_batch_size 16 \\\n",
        "    --save_steps 100 \\\n",
        "    --seed 42 \\\n",
        "    --do_predict \\\n",
        "    --overwrite_cache \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_total_limit 2 \\\n",
        "    --learning_rate 3e-05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bIftOiewuvEc",
        "outputId": "69f22935-635c-499c-8343-49eaed3b588e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-15 16:06:43.554409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-15 16:06:43.574256: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-15 16:06:43.580332: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-15 16:06:43.594939: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-15 16:06:44.766577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "08/15/2024 16:06:46 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "08/15/2024 16:06:46 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/ColabNotebooks/BERT/Tests/results/runs/Aug15_16-06-46_d361184ba2d6,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/ColabNotebooks/BERT/Tests/results,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/ColabNotebooks/BERT/Tests/results,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:731] 2024-08-15 16:06:46,981 >> loading configuration file /content/bert-base-ml-ner/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-08-15 16:06:46,984 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/bert-base-ml-ner\",\n",
            "  \"architectures\": [\n",
            "    \"BertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-QUE\",\n",
            "    \"1\": \"I-QUE\",\n",
            "    \"2\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-QUE\": 0,\n",
            "    \"I-QUE\": 1,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2267] 2024-08-15 16:06:46,985 >> loading file vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2267] 2024-08-15 16:06:46,985 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2267] 2024-08-15 16:06:46,985 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2267] 2024-08-15 16:06:46,985 >> loading file tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2267] 2024-08-15 16:06:46,985 >> loading file tokenizer.json\n",
            "[INFO|modeling_utils.py:3654] 2024-08-15 16:06:47,053 >> loading weights file /content/bert-base-ml-ner/model.safetensors\n",
            "[INFO|modeling_utils.py:4489] 2024-08-15 16:06:47,104 >> All model checkpoint weights were used when initializing BertForTokenClassification.\n",
            "\n",
            "[INFO|modeling_utils.py:4497] 2024-08-15 16:06:47,104 >> All the weights of BertForTokenClassification were initialized from the model checkpoint at /content/bert-base-ml-ner.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
            "[WARNING|training_args.py:2072] 2024-08-15 16:06:47,502 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - Creating features from dataset file at /content/drive/MyDrive/ColabNotebooks/BERT/Tests\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - Writing example 0 of 1\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - *** Example ***\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - guid: test-1\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - tokens: [CLS] implementar un esquema de base de datos que soporte seguimiento semanal y listas de tareas kan ##ban . [SEP]\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - input_ids: 4 19118 1044 14979 1009 2664 1009 2783 1041 10935 5852 20854 1040 8462 1009 6409 9239 1943 1008 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - label_ids: -100 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "08/15/2024 16:06:47 - INFO - utils_ner - Saving features into cached file /content/drive/MyDrive/ColabNotebooks/BERT/Tests/cached_test_BertTokenizer_128\n",
            "[INFO|trainer.py:3864] 2024-08-15 16:06:48,142 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:3866] 2024-08-15 16:06:48,142 >>   Num examples = 1\n",
            "[INFO|trainer.py:3869] 2024-08-15 16:06:48,143 >>   Batch size = 8\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100% 1/1 [00:00<00:00, 278.32it/s]\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_loss = 4.741683483123779\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_model_preparation_time = 0.0032\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_accuracy_score = 0.5882352941176471\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_precision = 0.0\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_recall = 0.0\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_f1 = 0.0\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_runtime = 1.3993\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_samples_per_second = 0.715\n",
            "08/15/2024 16:06:48 - INFO - __main__ -   test_steps_per_second = 0.715\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}